{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fd450a-7dd2-438a-ba05-a26148aa6e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBoost multiclassifier for roof materials in D.C.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, glob, time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e494fcfe-32ef-4f57-9161-d830e4e09c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping/code\n"
     ]
    }
   ],
   "source": [
    "# Functions!\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd8fe2e-8c01-4730-85ce-33d3db2977c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8223, 6714)\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (315267.0, 4294629.0, 335409.0, 4319298.0)\n",
      "sum: 9.873291015625\n",
      "CRS: EPSG:32618\n",
      "NoData: None\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, masked=True, cache=False).squeeze()\n",
    "print_raster(stack_da, open_file=False)\n",
    "band_names = stack_da.long_name\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29e3a84-ad5e-4f77-9ea1-f6f00b044983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nir',\n",
       " 'NDBIbg',\n",
       " 'NDBIrg',\n",
       " 'NISI',\n",
       " 'MNF1',\n",
       " 'NISI9x9',\n",
       " 'NISI27x27',\n",
       " 'class_code',\n",
       " 'uid']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_names = list(band_names)\n",
    "band_names.append('class_code')\n",
    "band_names.append('uid')\n",
    "band_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a29ed-8971-46dc-93ce-aea7781eb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the training data (footprints)\n",
    "# gdf_path = os.path.join(maindir,'data/spatial/mod/dc_data/training/dc_data_reference_footprints.gpkg')\n",
    "# ref = gpd.read_file(gdf_path)\n",
    "# footprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896824c9-bff9-4129-907f-e65840fd6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (sampled building footprints)\n",
    "######################################################\n",
    "\n",
    "# Footprints (from \"sample-stack.py\")\n",
    "ref_tbl_path_fp = os.path.join(maindir,'data/tabular/mod/dc_data/training/dc_data_reference_sampled_footprint.csv')\n",
    "ref = pd.read_csv(ref_tbl_path_fp)\n",
    "\n",
    "# Retain samples of band matches\n",
    "ref = ref[band_names]\n",
    "\n",
    "# Create a numeric class code\n",
    "class_mapping = {label: idx for idx, label in enumerate(ref['class_code'].unique())}\n",
    "ref['Y'] = ref['class_code'].map(class_mapping)\n",
    "\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838e9a2-12ce-4347-87aa-2e6a10929a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref['class_code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78ee0d-c08f-4af0-9e8e-1bbfadcf66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Set up the model data\n",
    "y = ref['Y']\n",
    "X = ref.drop(['class_code', 'uid', 'Y'], axis=1)\n",
    "\n",
    "# Define dataframes to store results for this feature set\n",
    "results = pd.DataFrame()  # to store the model performance metrics\n",
    "feat_imps = pd.DataFrame()  # to store the feature importances\n",
    "prob_preds = pd.DataFrame()  # for testing optimum cutoff\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = y.value_counts()\n",
    "total_samples = len(y)\n",
    "class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "print(f'Class weights: {class_weights}')\n",
    "\n",
    "# Set up the stratified K-fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop the folds\n",
    "fold_idx = 1\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(f'Fold: {fold_idx}')\n",
    "\n",
    "    # Split into train/test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Map class weights to each sample in the training set\n",
    "    sample_weights = y_train.map(class_weights).values\n",
    "    # print(sample_weights)\n",
    "\n",
    "    # Initialize the XGBoost classifier for multi-class classification\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective='multi:softmax',\n",
    "        num_class=len(np.unique(y)),\n",
    "        n_estimators=1001,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=8,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    xgb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    # Store feature importance\n",
    "    fold_imps = pd.DataFrame({\n",
    "        'Fold': fold_idx,\n",
    "        'Feature': X.columns,\n",
    "        'Importance': xgb_model.feature_importances_\n",
    "    })\n",
    "\n",
    "    feat_imps = pd.concat([feat_imps, fold_imps], axis=0)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    # Retrieve the accuracy/performance metrics\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the metrics into the results data frame\n",
    "    fold_results = pd.DataFrame({\n",
    "        'Fold': [fold_idx],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1': [f1],\n",
    "        'MCC': [mcc],\n",
    "        'Accuracy': [accuracy]\n",
    "    })\n",
    "    results = pd.concat([results, fold_results], ignore_index=True)\n",
    "\n",
    "    # Store the probability values for cutoff testing\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "    # Store probabilities and true labels\n",
    "    fold_probs = pd.DataFrame({\n",
    "        'TrueLabel': y_test,\n",
    "        'PredictedProb': list(y_pred_proba),\n",
    "        'Fold': fold_idx\n",
    "    })\n",
    "    prob_preds = pd.concat([prob_preds, fold_probs], ignore_index=True)\n",
    "\n",
    "    fold_idx += 1\n",
    "\n",
    "    del fold_probs, fold_results, fold_imps\n",
    "\n",
    "    t1 = (time.time() - t0) / 60\n",
    "    print(f\"Total elapsed time for fold {fold_idx}: {t1:.2f} minutes.\")\n",
    "    print(\"\\n~~~~~~~~~~\\n\")\n",
    "\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time: {t2:.2f} minutes.\")\n",
    "\n",
    "# # Append the feature set-specific results to the overall results dataframes\n",
    "# all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "# all_feat_imps = pd.concat([all_feat_imps, feat_imps], ignore_index=True)\n",
    "# all_prob_preds = pd.concat([all_prob_preds, prob_preds], ignore_index=True)\n",
    "\n",
    "# del results, feat_imps, prob_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca468c06-2dc4-4525-b23f-2237436c146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118160d7-5f09-45a0-95b9-f634ef04e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine true labels and predicted labels across all folds\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "for fold in range(1, fold_idx):\n",
    "    fold_data = prob_preds[prob_preds['Fold'] == fold]\n",
    "    all_true_labels.extend(fold_data['TrueLabel'])\n",
    "    all_pred_labels.extend(np.argmax(np.vstack(fold_data['PredictedProb']), axis=1))\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "disp.plot(ax=ax)\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig(os.path.join(maindir,'figures/FigX_xgboost_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89e8e9-2e32-4b96-811a-7357330c5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a classification report and convert it to a DataFrame\n",
    "cor_labels = [label for label, idx in sorted(class_mapping.items(), key=lambda item: item[1])]\n",
    "cr_df = pd.DataFrame(classification_report(all_true_labels, all_pred_labels, target_names=cor_labels, output_dict=True)).transpose()\n",
    "\n",
    "# Compute the average accuracy metrics across the 10 folds\n",
    "average_metrics = cr_df.loc[cor_labels].mean()\n",
    "\n",
    "# Display the DataFrame\n",
    "cr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515aca9-c573-42f1-8bd9-f6f5295fef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out the results\n",
    "results.to_csv(os.path.join(maindir,'xgboost_folds_results.csv'))\n",
    "feat_imps.to_csv(os.path.join(maindir,'xgboost_folds_feat_imps.csv'))\n",
    "prob_preds.to_csv(os.path.join(maindir,'xgboost_folds_prob_peds.csv'))\n",
    "cr_df.to_csv(os.path.join(maindir,'xgboost_classification_report_avg.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
