{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa48183d-8ae9-4080-95cc-ccf5da7dfd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping/results/resnet18/\n",
      "Imports successful !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrieve predicted probabilities for roof material classes from ResNet-18 models (CV)\n",
    "\"\"\"\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsat.models.classification import resnet18\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Custom functions (__functions.py)\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "results_dir = os.path.join(maindir, 'results/resnet18/')\n",
    "print(results_dir)\n",
    "\n",
    "print(\"Imports successful !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8f5bb37-f19f-4035-8ee2-60570baad0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_resnet_model(n_classes, n_bands, device, learning_rate, momentum, weight_decay, patience):\n",
    "    \"\"\"\n",
    "    Initializes the ResNet-18 model, optimizer, scheduler, scaler, and loss criterion.\n",
    "    \n",
    "    Args:\n",
    "        n_classes (int): Number of output classes.\n",
    "        n_bands (int): Number of input image bands.\n",
    "        device (torch.device): Device to run the model on (CPU/GPU).\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "        momentum (float): Momentum for SGD optimizer.\n",
    "        weight_decay (float): Weight decay for SGD optimizer.\n",
    "        patience (int): Patience for learning rate scheduler.\n",
    "\n",
    "    Returns:\n",
    "        model (torch.nn.Module): The initialized model.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer.\n",
    "        lr_scheduler (torch.optim.lr_scheduler): The learning rate scheduler.\n",
    "        scaler (torch.cuda.amp.GradScaler): The scaler for mixed precision.\n",
    "    \"\"\"\n",
    "    # Initialize the Resnet-18 model\n",
    "    model = resnet18(n_classes, in_channels=n_bands, pretrained=False)\n",
    "    # Move the model to the specified device\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model = nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        print('Made CPU parallel')\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    # Define the learning rate scheduler\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, verbose=False, min_lr=1e-6)\n",
    "    \n",
    "    # Initialize the scaler for mixed precision\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    return model, optimizer, lr_scheduler, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cd14c-28bc-46c5-980f-591552d6a670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "404cfb2f-e84b-401c-a66e-3a47427374ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8223, 6714)\n",
      "bands: 6\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (315267.0, 4294629.0, 335409.0, 4319298.0)\n",
      "sum: 8.181640625\n",
      "CRS: EPSG:32618\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 6, y: 8223, x: 6714)> Size: 1GB\n",
      "[331255332 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 48B 1 2 3 4 5 6\n",
      "  * x            (x) float64 54kB 3.153e+05 3.153e+05 ... 3.354e+05 3.354e+05\n",
      "  * y            (y) float64 66kB 4.319e+06 4.319e+06 ... 4.295e+06 4.295e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    long_name:      ('nir', 'NDBIbg', 'NDBIrg', 'NISI', 'MNF1', 'NISI5x5')\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "# stack_da_fp = os.path.join(homedir,'opp-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60916efd-376d-488d-b3a1-3ee3020638a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59aa4c7-d3af-48ec-a2a1-9a75c56886a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform predictions on the holdout data for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf09415-0403-4ac7-931c-be147116a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967b8cf0-3ed2-45b0-b788-c3a214b3d865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout set class distribution:\n",
      " class_code  code\n",
      "CS          0       7427\n",
      "ME          1       7373\n",
      "SL          2       3054\n",
      "UR          3        256\n",
      "WS          5        231\n",
      "TL          4        185\n",
      "SH          6        157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data\n",
    "holdout_df = gpd.read_file(os.path.join(results_dir, 'cv-results/dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "print(\"Holdout set class distribution:\\n\", holdout_df[['class_code','code']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6916217e-6df9-467a-adb6-ced7b0674e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code map: \n",
      "{0: 'CS', 1: 'ME', 2: 'SL', 3: 'UR', 4: 'TL', 5: 'WS', 6: 'SH'}\n",
      "Description map: \n",
      "{0: 'Composition Shingle', 1: 'Metal', 2: 'Slate', 3: 'Urethane', 4: 'Tile', 5: 'Wood shake/shingle', 6: 'Shingle'}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for mapping\n",
    "code_mapping = dict(zip(holdout_df['code'], holdout_df['class_code']))  # Mapping to original 'class_code'\n",
    "desc_mapping = dict(zip(holdout_df['code'], holdout_df['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2551746-50a0-4f98-a2c1-f82588d203b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c29a7d-3e50-44e9-ae4c-b7770749b455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout data loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data into Torch\n",
    "holdout_ds = RoofImageDatasetPlanet(holdout_df[['geometry', 'code']], img_path=stack_da_fp, n_bands=n_bands, img_dim=params['window_size'])\n",
    "holdout_loader = DataLoader(holdout_ds, batch_size=params['batch_size'] * 2, num_workers=2, shuffle=False, pin_memory=True)\n",
    "print(\"Holdout data loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eca1ab8d-1365-472a-928e-230ef70e0f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for model eval ...\n"
     ]
    }
   ],
   "source": [
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model eval ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb7b725-a2b6-420f-b2ef-60f92fff41e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions with model from fold 1\n",
      "Loading model from path: /Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping/results/resnet18/cv-models/dc-resnet18_fold1.pth\n",
      "Made CPU parallel\n",
      "\tProcessed 0 samples\n",
      "\tProcessed 640 samples\n",
      "\tProcessed 1280 samples\n",
      "\tProcessed 1920 samples\n",
      "\tProcessed 2560 samples\n",
      "\tProcessed 3200 samples\n",
      "\tProcessed 3840 samples\n",
      "\tProcessed 4480 samples\n",
      "\tProcessed 5120 samples\n",
      "\tProcessed 5760 samples\n",
      "\tProcessed 6400 samples\n",
      "\tProcessed 7040 samples\n",
      "\tProcessed 7680 samples\n",
      "\tProcessed 8320 samples\n",
      "\tProcessed 8960 samples\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Add predicted probabilities for each class as seperate columns\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[0;32m---> 69\u001b[0m     class_label \u001b[38;5;241m=\u001b[39m \u001b[43mclass_mapping\u001b[49m[class_idx]\n\u001b[1;32m     70\u001b[0m     fold_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [prob[class_idx] \u001b[38;5;28;01mfor\u001b[39;00m prob \u001b[38;5;129;01min\u001b[39;00m pred_probs]\n\u001b[1;32m     72\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mappend(fold_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "n_classes = len(code_mapping.keys())\n",
    "\n",
    "# Initialize list to store the results:\n",
    "all_preds = []\n",
    "# loop the trained models and make predictions\n",
    "for fold_idx in range(1, n_folds + 1):\n",
    "    print(f\"Making predictions with model from fold {fold_idx}\")\n",
    "\n",
    "    # Load the trained model for the current fold\n",
    "    model_fp = os.path.join(results_dir, f'cv-models/dc-resnet18_fold{fold_idx}.pth')\n",
    "    print(f\"Loading model from path: {model_fp}\")\n",
    "    checkpoint = torch.load(model_fp, map_location=device)\n",
    "\n",
    "    # Initialize the model architecture\n",
    "    model, _, _, _ = initialize_resnet_model(\n",
    "        n_classes=n_classes,\n",
    "        n_bands=n_bands,\n",
    "        device=device,\n",
    "        learning_rate=params['learning_rate'],\n",
    "        momentum=params['momentum'],\n",
    "        weight_decay=params['weight_decay'],\n",
    "        patience=params['patience']\n",
    "    )\n",
    "\n",
    "    # Load the trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    true_codes = []\n",
    "    pred_codes = []\n",
    "    pred_probs = [] \n",
    "    \n",
    "    # Make predictions on the holdout data\n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(holdout_loader):\n",
    "            image, label = sample['image'].to(device), sample['code'].to(device)\n",
    "\n",
    "            # Get the model's predictions\n",
    "            output = model(image.float())\n",
    "            # Apply softmax to get probabilities\n",
    "            probabilities = softmax(output, dim=1).cpu().numpy()\n",
    "            # Apply argmax to get the predicted class\n",
    "            predictions = output.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "            # Store true labels, predictions, and probabilities\n",
    "            true_codes.extend(label.cpu().numpy())\n",
    "            pred_codes.extend(predictions)\n",
    "            pred_probs.extend(probabilities)\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"\\tProcessed {idx * params['batch_size']} samples\")\n",
    "\n",
    "    # Map true and predicted labels to their class codes\n",
    "    true_class_codes = [code_mapping[code] for code in true_codes]\n",
    "    pred_class_codes = [code_mapping[pred] for pred in pred_codes]\n",
    "\n",
    "    # Store true and predicted labels in a dataframe\n",
    "    fold_df = pd.DataFrame({\n",
    "        'fold_idx': fold_idx,         \n",
    "        'true_code': true_codes,\n",
    "        'pred_code': pred_codes,\n",
    "        'true_label': true_class_codes,\n",
    "        'pred_label': pred_class_codes\n",
    "    })\n",
    "\n",
    "    # Add predicted probabilities for each class as seperate columns\n",
    "    for class_idx in range(n_classes):\n",
    "        class_label = code_mapping[class_idx]\n",
    "        fold_df[f\"{class_label}\"] = [prob[class_idx] for prob in pred_probs]\n",
    "    \n",
    "    all_preds.append(fold_df)\n",
    "\n",
    "    del model\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# concatenate across folds\n",
    "preds_df = pd.concat(all_preds, ignore_index=True)\n",
    "\n",
    "# Save the predictions for later analysis\n",
    "preds_df.to_csv(os.path.join(results_dir, 'cv-results/dc-resnet18_cv_holdout_prob_preds.csv'), index=False)\n",
    "print(\"Completed predictions for all folds!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
