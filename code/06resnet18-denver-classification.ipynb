{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6f7f5a-e411-45df-b25d-c461d6d0cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/results/resnet18-cv/\n",
      "Imports successful !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classifying roof materials for building footprints from trained ResNet-18 models\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, gc, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsat.models.classification import resnet18\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Custom functions (__functions.py)\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "homedir = '/home/jovyan' # cyverse\n",
    "\n",
    "# results_dir = os.path.join(maindir, 'results/resnet18/')\n",
    "results_dir = os.path.join(homedir, 'results/resnet18-cv/')\n",
    "print(results_dir)\n",
    "\n",
    "print(\"Imports successful !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e13273e-b85d-4273-bda6-9011f226e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec9d0-e485-43de-a674-11b089ce305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b9945-1891-4861-ada1-bbc177de5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MS building footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac52412-7d3d-438b-8ff7-510c2d13f1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((334794.168 4306846.311, 334799.662 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((334703.572 4306870.743, 334701.114 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((334666.123 4306432.288, 334671.751 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((334616.324 4306162.858, 334621.692 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((334622.665 4306603.184, 334630.936 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                           geometry\n",
       "0    1  POLYGON ((334794.168 4306846.311, 334799.662 4...\n",
       "1    2  POLYGON ((334703.572 4306870.743, 334701.114 4...\n",
       "2    3  POLYGON ((334666.123 4306432.288, 334671.751 4...\n",
       "3    4  POLYGON ((334616.324 4306162.858, 334621.692 4...\n",
       "4    5  POLYGON ((334622.665 4306603.184, 334630.936 4..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join(maindir, 'data/spatial/raw/dc_data/footprints/dc-ms_footprints.gpkg')\n",
    "# fp = os.path.join(homedir, 'OPP/training/dc/dc-ms_footprints.gpkg')\n",
    "footprints = gpd.read_file(fp)\n",
    "footprints['uid'] = footprints.index + 1\n",
    "footprints = footprints[['uid', 'geometry']]\n",
    "footprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf17997-cc95-4b0f-bb12-b5b86d9dabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled data as well (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e37f302-1aeb-4221-9ea8-8d4d7c975e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout set class distribution:\n",
      " class_code  code\n",
      "CS          0       7427\n",
      "ME          1       7373\n",
      "SL          2       3054\n",
      "UR          3        256\n",
      "WS          5        231\n",
      "TL          4        185\n",
      "SH          6        157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data\n",
    "holdout_df = gpd.read_file(os.path.join(maindir,'results/resnet18/cv-results/dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "# holdout_df = gpd.read_file(os.path.join(results_dir, 'dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "print(\"Holdout set class distribution:\\n\", holdout_df[['class_code','code']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5ebcb8b-d03f-4ba6-a150-2610d863445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code map: \n",
      "{0: 'CS', 1: 'ME', 2: 'SL', 3: 'UR', 4: 'TL', 5: 'WS', 6: 'SH'}\n",
      "Description map: \n",
      "{0: 'Composition Shingle', 1: 'Metal', 2: 'Slate', 3: 'Urethane', 4: 'Tile', 5: 'Wood shake/shingle', 6: 'Shingle'}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for mapping\n",
    "code_mapping = dict(zip(holdout_df['code'], holdout_df['class_code']))  # Mapping to original 'class_code'\n",
    "desc_mapping = dict(zip(holdout_df['code'], holdout_df['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e5b4d-0625-4d3f-b747-bae45e703674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f74f8c-5a20-4dc5-9037-28f9fbfef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Planet imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe0b7f7-8c28-4580-b912-cf5983fc437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8223, 6714)\n",
      "bands: 6\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (315267.0, 4294629.0, 335409.0, 4319298.0)\n",
      "sum: 8.181640625\n",
      "CRS: EPSG:32618\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 6, y: 8223, x: 6714)> Size: 1GB\n",
      "[331255332 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 48B 1 2 3 4 5 6\n",
      "  * x            (x) float64 54kB 3.153e+05 3.153e+05 ... 3.354e+05 3.354e+05\n",
      "  * y            (y) float64 66kB 4.319e+06 4.319e+06 ... 4.295e+06 4.295e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    long_name:      ('nir', 'NDBIbg', 'NDBIrg', 'NISI', 'MNF1', 'NISI5x5')\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "# stack_da_fp = os.path.join(homedir,'opp-data/denver_0815_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2f3a8-13ea-45f0-976e-b84ce059a813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59417723-bfeb-4198-869a-d49cb60b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roof image dataset for inference (all MS building footprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af3fc73-0931-4082-b1c8-875c3163e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded !\n"
     ]
    }
   ],
   "source": [
    "footprints_ds = UnlabeledRoofImageDataset(footprints, img_path=stack_da_fp, n_bands=n_bands, img_dim=params['window_size'])\n",
    "dloader = DataLoader(\n",
    "    footprints_ds, \n",
    "    batch_size=params['batch_size'], \n",
    "    num_workers=2, \n",
    "    shuffle=False, \n",
    "    pin_memory=True\n",
    ")\n",
    "print(\"Data loaded for all footprints !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18eafa4-f677-4b31-a090-9bbaaa933792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad058ea1-d142-4394-9cb4-4282cbdb135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet-18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e68f3-3771-4727-8a13-77716be22079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbb8eb4-e469-491f-9ed3-b2b7376c57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for model eval ...\n"
     ]
    }
   ],
   "source": [
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model eval ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b2970e-bcc3-401e-b48a-7790ab1b4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from path: /Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping/results/resnet18/cv-models/dc-resnet18_fold4.pth\n",
      "\tMade CPU parallel.\n",
      "\tModel loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for the current fold\n",
    "best_fold = 4  # from holdout accuracy\n",
    "model_fp = os.path.join(maindir,f'results/resnet18/cv-models/dc-resnet18_fold{best_fold}.pth')\n",
    "# model_fp = os.path.join(results_dir, f'dc-resnet18_fold{best_fold}.pth')\n",
    "\n",
    "print(f\"Loading model from path: {model_fp}\")\n",
    "checkpoint = torch.load(model_fp, map_location=device)\n",
    "\n",
    "# Initialize the model architecture\n",
    "n_classes = len(code_mapping.keys())\n",
    "model, _, _, _ = initialize_resnet18(\n",
    "    n_classes=n_classes,\n",
    "    n_channels=n_bands,\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(\"\\tModel loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e21f2-acb4-41ff-ba8b-f34a973d89a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e53cf992-bf2c-4b41-88a4-f5756eda02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of footprint dataset: 77851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>CS</th>\n",
       "      <th>ME</th>\n",
       "      <th>SL</th>\n",
       "      <th>UR</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_idx bbox prediction confidence   CS   ME   SL   UR   TL   WS   SH\n",
       "0       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "1       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "2       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "n = footprints_ds.__len__() # length of the dataset\n",
    "class_labels = [code_mapping[i] for i in range(n_classes)]\n",
    "print(f\"Length of footprint dataset: {n}\")\n",
    "columns=['chunk_idx', 'bbox', 'prediction', 'confidence'] + class_labels\n",
    "res_df = pd.DataFrame(\n",
    "    columns=columns,\n",
    "    index=range(n)\n",
    ")\n",
    "res_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3255b37b-3a93-4bd9-a3b1-7d5441cdc19a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t0 \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(dloader):\n",
    "        image = sample['image'].to(device) # retrieve the image chunks (unlabeled)\n",
    "        bboxes = sample['bbox']  # Get the bounding boxes for the image chunks\n",
    "\n",
    "        # Make predictions\n",
    "        output = model(image.float())\n",
    "        probabilities = softmax(output, dim=1).cpu().numpy()  # Get probabilities for all classes\n",
    "        predictions = output.argmax(dim=1).cpu().numpy() # the predicted class\n",
    "        confidence = probabilities.max(axis=1)  # max probability for the predicted class\n",
    "\n",
    "        # Assign predictions and probabilities to all footprints that intersect with the bounding box\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            prob_dict = {code_mapping[j]: probabilities[i, j] for j in range(n_classes)}  # Use class names as column headers\n",
    "            res_df = res_df.append({\n",
    "                'chunk_idx': batch_idx * params['batch_size'] + i,  # Optional chunk ID\n",
    "                'bbox': bbox,  # Bounding box of the chunk\n",
    "                'prediction': code_mapping[predictions[i]],  # Map prediction to class name\n",
    "                'confidence': confidence[i],\n",
    "                **prob_dict  # Include all class probabilities with class names as column headers\n",
    "            }, ignore_index=True)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\tProcessed {batch_idx * params['batch_size']} samples.\")\n",
    "\n",
    "        # Clear GPU memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time for inference: {t2:.2f} minutes.\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e619376-4490-4140-a887-e7dde8c4779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = os.path.join(results_dir,'classification/dc-resnet18-inference_ms-footprints.csv')\n",
    "res_df.to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d400536-86b7-47fe-a7b4-debe0e9e5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2ec4c-9fb9-492a-a475-794b91bd6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
