{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6f7f5a-e411-45df-b25d-c461d6d0cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/results/resnet18-cv/\n",
      "Imports successful !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classifying roof materials for building footprints from trained ResNet-18 models\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, gc, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsat.models.classification import resnet18\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Custom functions (__functions.py)\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "homedir = '/home/jovyan' # cyverse\n",
    "\n",
    "# results_dir = os.path.join(maindir, 'results/resnet18/')\n",
    "results_dir = os.path.join(homedir, 'results/resnet18-cv/')\n",
    "print(results_dir)\n",
    "\n",
    "proj = 'EPSG:32613'\n",
    "\n",
    "print(\"Imports successful !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e13273e-b85d-4273-bda6-9011f226e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec9d0-e485-43de-a674-11b089ce305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b2b9945-1891-4861-ada1-bbc177de5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MS building footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac52412-7d3d-438b-8ff7-510c2d13f1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((508060.415 4398334.066, 508060.659 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((508048.832 4395402.828, 508034.603 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((508035.125 4408152.316, 508022.631 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((508027.602 4409939.978, 508015.196 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((508026.68 4409187.594, 508026.841 44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                           geometry\n",
       "0    1  POLYGON ((508060.415 4398334.066, 508060.659 4...\n",
       "1    2  POLYGON ((508048.832 4395402.828, 508034.603 4...\n",
       "2    3  POLYGON ((508035.125 4408152.316, 508022.631 4...\n",
       "3    4  POLYGON ((508027.602 4409939.978, 508015.196 4...\n",
       "4    5  POLYGON ((508026.68 4409187.594, 508026.841 44..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp = os.path.join(maindir, 'data/spatial/raw/denver_data/footprints/denver-ms_footprints.gpkg')\n",
    "fp = os.path.join(homedir, 'opp-data/denver-ms_footprints.gpkg')\n",
    "footprints = gpd.read_file(fp)\n",
    "footprints['uid'] = footprints.index + 1\n",
    "footprints = footprints[['uid', 'geometry']]\n",
    "footprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fd57ca-4032-4bc8-bedb-24200302d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:32613>\n",
       "Name: WGS 84 / UTM zone 13N\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Between 108°W and 102°W, northern hemisphere between equator and 84°N, onshore and offshore. Canada - Northwest Territories (NWT); Nunavut; Saskatchewan. Mexico. United States (USA).\n",
       "- bounds: (-108.0, 0.0, -102.0, 84.0)\n",
       "Coordinate Operation:\n",
       "- name: UTM zone 13N\n",
       "- method: Transverse Mercator\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprints.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649722cd-911b-4c2a-b8b2-96278124a421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf17997-cc95-4b0f-bb12-b5b86d9dabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled data as well (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e37f302-1aeb-4221-9ea8-8d4d7c975e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout set class distribution:\n",
      " class_code  code\n",
      "CS          6       17313\n",
      "WS          1        2129\n",
      "AP          3        1624\n",
      "TL          0         569\n",
      "CN          2         552\n",
      "TG          5          46\n",
      "SL          4          46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data\n",
    "# holdout_df = gpd.read_file(os.path.join(homedir,'results/resnet18/cv-results/ddenver-resnet18_cv_holdout_ref.gpkg'))\n",
    "holdout_df = gpd.read_file(os.path.join(results_dir, 'denver-resnet18_cv_holdout_ref.gpkg'))\n",
    "print(\"Holdout set class distribution:\\n\", holdout_df[['class_code','code']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5ebcb8b-d03f-4ba6-a150-2610d863445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code map: \n",
      "{0: 'TL', 1: 'WS', 2: 'CN', 3: 'AP', 4: 'SL', 5: 'TG', 6: 'CS'}\n",
      "Description map: \n",
      "{0: 'Tile', 1: 'Wood shake/shingle', 2: 'Concrete', 3: 'Asphalt', 4: 'Slate', 5: 'Tar and gravel', 6: 'Composition Shingle'}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for mapping\n",
    "code_mapping = dict(zip(holdout_df['code'], holdout_df['class_code']))  # Mapping to original 'class_code'\n",
    "desc_mapping = dict(zip(holdout_df['code'], holdout_df['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e5b4d-0625-4d3f-b747-bae45e703674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f74f8c-5a20-4dc5-9037-28f9fbfef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Planet imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe0b7f7-8c28-4580-b912-cf5983fc437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (14939, 6330)\n",
      "bands: 6\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (489558.0, 4383960.0, 508548.0, 4428777.0)\n",
      "sum: 15.8248291015625\n",
      "CRS: EPSG:32613\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 6, y: 14939, x: 6330)> Size: 2GB\n",
      "[567383220 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 48B 1 2 3 4 5 6\n",
      "  * x            (x) float64 51kB 4.896e+05 4.896e+05 ... 5.085e+05 5.085e+05\n",
      "  * y            (y) float64 120kB 4.429e+06 4.429e+06 ... 4.384e+06 4.384e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    long_name:      ('nir', 'NDBIbg', 'NDBIrg', 'NISI', 'MNF1', 'NISI5x5')\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "# stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0815_psscene8b_final_norm.tif')\n",
    "stack_da_fp = os.path.join(homedir,'opp-data/denver_0815_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2f3a8-13ea-45f0-976e-b84ce059a813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59417723-bfeb-4198-869a-d49cb60b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roof image dataset for inference (all MS building footprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3709bb22-0465-4a09-967b-5267a52f3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function to handle Tensors and shapely.geometry.Polygon objects\n",
    "def custom_collate(batch):\n",
    "    images = torch.stack([item['image'] for item in batch], dim=0)  # Batch the images (Tensors)\n",
    "    bboxes = [item['bbox'] for item in batch]  # Keep bounding boxes as a list (don't batch them)\n",
    "    return {'image': images, 'bbox': bboxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af3fc73-0931-4082-b1c8-875c3163e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for all footprints !\n"
     ]
    }
   ],
   "source": [
    "footprints_ds = UnlabeledRoofImageDataset(footprints, img_path=stack_da_fp, n_bands=n_bands, img_dim=params['window_size'])\n",
    "dloader = DataLoader(\n",
    "    footprints_ds, \n",
    "    batch_size=params['batch_size']*2, \n",
    "    num_workers=2, \n",
    "    shuffle=False, \n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate # allow retrieving the bbox\n",
    ")\n",
    "print(\"Data loaded for all footprints !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18eafa4-f677-4b31-a090-9bbaaa933792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad058ea1-d142-4394-9cb4-4282cbdb135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet-18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e68f3-3771-4727-8a13-77716be22079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cbb8eb4-e469-491f-9ed3-b2b7376c57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for model eval ...\n"
     ]
    }
   ],
   "source": [
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model eval ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b2970e-bcc3-401e-b48a-7790ab1b4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from path: /home/jovyan/results/resnet18-cv/denver-resnet18_fold3.pth\n",
      "\tMade GPU parallel.\n",
      "\tModel loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for the current fold\n",
    "best_fold = 3  # from holdout accuracy\n",
    "# model_fp = os.path.join(maindir,f'results/resnet18/cv-models/denver-resnet18_fold{best_fold}.pth')\n",
    "model_fp = os.path.join(results_dir, f'denver-resnet18_fold{best_fold}.pth')\n",
    "\n",
    "print(f\"Loading model from path: {model_fp}\")\n",
    "checkpoint = torch.load(model_fp, map_location=device)\n",
    "\n",
    "# Initialize the model architecture\n",
    "n_classes = len(code_mapping.keys())\n",
    "model, _, _, _ = initialize_resnet18(\n",
    "    n_classes=n_classes,\n",
    "    n_channels=n_bands,\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(\"\\tModel loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e21f2-acb4-41ff-ba8b-f34a973d89a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e53cf992-bf2c-4b41-88a4-f5756eda02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of footprint dataset: 400195\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>CN</th>\n",
       "      <th>AP</th>\n",
       "      <th>SL</th>\n",
       "      <th>TG</th>\n",
       "      <th>CS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chunk_idx, bbox, prediction, confidence, TL, WS, CN, AP, SL, TG, CS]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "n = footprints_ds.__len__() # length of the dataset\n",
    "print(f\"Length of footprint dataset: {n}\")\n",
    "class_labels = [code_mapping[i] for i in range(n_classes)]\n",
    "columns = ['chunk_idx', 'bbox', 'prediction', 'confidence'] + class_labels\n",
    "res_df = pd.DataFrame(columns=columns)\n",
    "res_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3255b37b-3a93-4bd9-a3b1-7d5441cdc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessed 0 samples.\n",
      "\tProcessed 640 samples.\n",
      "\tProcessed 1280 samples.\n",
      "\tProcessed 1920 samples.\n",
      "\tProcessed 2560 samples.\n",
      "\tProcessed 3200 samples.\n",
      "\tProcessed 3840 samples.\n",
      "\tProcessed 4480 samples.\n",
      "\tProcessed 5120 samples.\n",
      "\tProcessed 5760 samples.\n",
      "\tProcessed 6400 samples.\n",
      "\tProcessed 7040 samples.\n",
      "\tProcessed 7680 samples.\n",
      "\tProcessed 8320 samples.\n",
      "\tProcessed 8960 samples.\n",
      "\tProcessed 9600 samples.\n",
      "\tProcessed 10240 samples.\n",
      "\tProcessed 10880 samples.\n",
      "\tProcessed 11520 samples.\n",
      "\tProcessed 12160 samples.\n",
      "\tProcessed 12800 samples.\n",
      "\tProcessed 13440 samples.\n",
      "\tProcessed 14080 samples.\n",
      "\tProcessed 14720 samples.\n",
      "\tProcessed 15360 samples.\n",
      "\tProcessed 16000 samples.\n",
      "\tProcessed 16640 samples.\n",
      "\tProcessed 17280 samples.\n",
      "\tProcessed 17920 samples.\n",
      "\tProcessed 18560 samples.\n",
      "\tProcessed 19200 samples.\n",
      "\tProcessed 19840 samples.\n",
      "\tProcessed 20480 samples.\n",
      "\tProcessed 21120 samples.\n",
      "\tProcessed 21760 samples.\n",
      "\tProcessed 22400 samples.\n",
      "\tProcessed 23040 samples.\n",
      "\tProcessed 23680 samples.\n",
      "\tProcessed 24320 samples.\n",
      "\tProcessed 24960 samples.\n",
      "\tProcessed 25600 samples.\n",
      "\tProcessed 26240 samples.\n",
      "\tProcessed 26880 samples.\n",
      "\tProcessed 27520 samples.\n",
      "\tProcessed 28160 samples.\n",
      "\tProcessed 28800 samples.\n",
      "\tProcessed 29440 samples.\n",
      "\tProcessed 30080 samples.\n",
      "\tProcessed 30720 samples.\n",
      "\tProcessed 31360 samples.\n",
      "\tProcessed 32000 samples.\n",
      "\tProcessed 32640 samples.\n",
      "\tProcessed 33280 samples.\n",
      "\tProcessed 33920 samples.\n",
      "\tProcessed 34560 samples.\n",
      "\tProcessed 35200 samples.\n",
      "\tProcessed 35840 samples.\n",
      "\tProcessed 36480 samples.\n",
      "\tProcessed 37120 samples.\n",
      "\tProcessed 37760 samples.\n",
      "\tProcessed 38400 samples.\n",
      "\tProcessed 39040 samples.\n",
      "\tProcessed 39680 samples.\n",
      "\tProcessed 40320 samples.\n",
      "\tProcessed 40960 samples.\n",
      "\tProcessed 41600 samples.\n",
      "\tProcessed 42240 samples.\n",
      "\tProcessed 42880 samples.\n",
      "\tProcessed 43520 samples.\n",
      "\tProcessed 44160 samples.\n",
      "\tProcessed 44800 samples.\n",
      "\tProcessed 45440 samples.\n",
      "\tProcessed 46080 samples.\n",
      "\tProcessed 46720 samples.\n",
      "\tProcessed 47360 samples.\n",
      "\tProcessed 48000 samples.\n",
      "\tProcessed 48640 samples.\n",
      "\tProcessed 49280 samples.\n",
      "\tProcessed 49920 samples.\n",
      "\tProcessed 50560 samples.\n",
      "\tProcessed 51200 samples.\n",
      "\tProcessed 51840 samples.\n",
      "\tProcessed 52480 samples.\n",
      "\tProcessed 53120 samples.\n",
      "\tProcessed 53760 samples.\n",
      "\tProcessed 54400 samples.\n",
      "\tProcessed 55040 samples.\n",
      "\tProcessed 55680 samples.\n",
      "\tProcessed 56320 samples.\n",
      "\tProcessed 56960 samples.\n",
      "\tProcessed 57600 samples.\n",
      "\tProcessed 58240 samples.\n",
      "\tProcessed 58880 samples.\n",
      "\tProcessed 59520 samples.\n",
      "\tProcessed 60160 samples.\n",
      "\tProcessed 60800 samples.\n",
      "\tProcessed 61440 samples.\n",
      "\tProcessed 62080 samples.\n",
      "\tProcessed 62720 samples.\n",
      "\tProcessed 63360 samples.\n",
      "\tProcessed 64000 samples.\n",
      "\tProcessed 64640 samples.\n",
      "\tProcessed 65280 samples.\n",
      "\tProcessed 65920 samples.\n",
      "\tProcessed 66560 samples.\n",
      "\tProcessed 67200 samples.\n",
      "\tProcessed 67840 samples.\n",
      "\tProcessed 68480 samples.\n",
      "\tProcessed 69120 samples.\n",
      "\tProcessed 69760 samples.\n",
      "\tProcessed 70400 samples.\n",
      "\tProcessed 71040 samples.\n",
      "\tProcessed 71680 samples.\n",
      "\tProcessed 72320 samples.\n",
      "\tProcessed 72960 samples.\n",
      "\tProcessed 73600 samples.\n",
      "\tProcessed 74240 samples.\n",
      "\tProcessed 74880 samples.\n",
      "\tProcessed 75520 samples.\n",
      "\tProcessed 76160 samples.\n",
      "\tProcessed 76800 samples.\n",
      "\tProcessed 77440 samples.\n",
      "\tProcessed 78080 samples.\n",
      "\tProcessed 78720 samples.\n",
      "\tProcessed 79360 samples.\n",
      "\tProcessed 80000 samples.\n",
      "\tProcessed 80640 samples.\n",
      "\tProcessed 81280 samples.\n",
      "\tProcessed 81920 samples.\n",
      "\tProcessed 82560 samples.\n",
      "\tProcessed 83200 samples.\n",
      "\tProcessed 83840 samples.\n",
      "\tProcessed 84480 samples.\n",
      "\tProcessed 85120 samples.\n",
      "\tProcessed 85760 samples.\n",
      "\tProcessed 86400 samples.\n",
      "\tProcessed 87040 samples.\n",
      "\tProcessed 87680 samples.\n",
      "\tProcessed 88320 samples.\n",
      "\tProcessed 88960 samples.\n",
      "\tProcessed 89600 samples.\n",
      "\tProcessed 90240 samples.\n",
      "\tProcessed 90880 samples.\n",
      "\tProcessed 91520 samples.\n",
      "\tProcessed 92160 samples.\n",
      "\tProcessed 92800 samples.\n",
      "\tProcessed 93440 samples.\n",
      "\tProcessed 94080 samples.\n",
      "\tProcessed 94720 samples.\n",
      "\tProcessed 95360 samples.\n",
      "\tProcessed 96000 samples.\n",
      "\tProcessed 96640 samples.\n",
      "\tProcessed 97280 samples.\n",
      "\tProcessed 97920 samples.\n",
      "\tProcessed 98560 samples.\n",
      "\tProcessed 99200 samples.\n",
      "\tProcessed 99840 samples.\n",
      "\tProcessed 100480 samples.\n",
      "\tProcessed 101120 samples.\n",
      "\tProcessed 101760 samples.\n",
      "\tProcessed 102400 samples.\n",
      "\tProcessed 103040 samples.\n",
      "\tProcessed 103680 samples.\n",
      "\tProcessed 104320 samples.\n",
      "\tProcessed 104960 samples.\n",
      "\tProcessed 105600 samples.\n",
      "\tProcessed 106240 samples.\n",
      "\tProcessed 106880 samples.\n",
      "\tProcessed 107520 samples.\n",
      "\tProcessed 108160 samples.\n",
      "\tProcessed 108800 samples.\n",
      "\tProcessed 109440 samples.\n",
      "\tProcessed 110080 samples.\n",
      "\tProcessed 110720 samples.\n",
      "\tProcessed 111360 samples.\n",
      "\tProcessed 112000 samples.\n",
      "\tProcessed 112640 samples.\n",
      "\tProcessed 113280 samples.\n",
      "\tProcessed 113920 samples.\n",
      "\tProcessed 114560 samples.\n",
      "\tProcessed 115200 samples.\n",
      "\tProcessed 115840 samples.\n",
      "\tProcessed 116480 samples.\n",
      "\tProcessed 117120 samples.\n",
      "\tProcessed 117760 samples.\n",
      "\tProcessed 118400 samples.\n",
      "\tProcessed 119040 samples.\n",
      "\tProcessed 119680 samples.\n",
      "\tProcessed 120320 samples.\n",
      "\tProcessed 120960 samples.\n",
      "\tProcessed 121600 samples.\n",
      "\tProcessed 122240 samples.\n",
      "\tProcessed 122880 samples.\n",
      "\tProcessed 123520 samples.\n",
      "\tProcessed 124160 samples.\n",
      "\tProcessed 124800 samples.\n",
      "\tProcessed 125440 samples.\n",
      "\tProcessed 126080 samples.\n",
      "\tProcessed 126720 samples.\n",
      "\tProcessed 127360 samples.\n",
      "\tProcessed 128000 samples.\n",
      "\tProcessed 128640 samples.\n",
      "\tProcessed 129280 samples.\n",
      "\tProcessed 129920 samples.\n",
      "\tProcessed 130560 samples.\n",
      "\tProcessed 131200 samples.\n",
      "\tProcessed 131840 samples.\n",
      "\tProcessed 132480 samples.\n",
      "\tProcessed 133120 samples.\n",
      "\tProcessed 133760 samples.\n",
      "\tProcessed 134400 samples.\n",
      "\tProcessed 135040 samples.\n",
      "\tProcessed 135680 samples.\n",
      "\tProcessed 136320 samples.\n",
      "\tProcessed 136960 samples.\n",
      "\tProcessed 137600 samples.\n",
      "\tProcessed 138240 samples.\n",
      "\tProcessed 138880 samples.\n",
      "\tProcessed 139520 samples.\n",
      "\tProcessed 140160 samples.\n",
      "\tProcessed 140800 samples.\n",
      "\tProcessed 141440 samples.\n",
      "\tProcessed 142080 samples.\n",
      "\tProcessed 142720 samples.\n",
      "\tProcessed 143360 samples.\n",
      "\tProcessed 144000 samples.\n",
      "\tProcessed 144640 samples.\n",
      "\tProcessed 145280 samples.\n",
      "\tProcessed 145920 samples.\n",
      "\tProcessed 146560 samples.\n",
      "\tProcessed 147200 samples.\n",
      "\tProcessed 147840 samples.\n",
      "\tProcessed 148480 samples.\n",
      "\tProcessed 149120 samples.\n",
      "\tProcessed 149760 samples.\n",
      "\tProcessed 150400 samples.\n",
      "\tProcessed 151040 samples.\n",
      "\tProcessed 151680 samples.\n",
      "\tProcessed 152320 samples.\n",
      "\tProcessed 152960 samples.\n",
      "\tProcessed 153600 samples.\n",
      "\tProcessed 154240 samples.\n",
      "\tProcessed 154880 samples.\n",
      "\tProcessed 155520 samples.\n",
      "\tProcessed 156160 samples.\n",
      "\tProcessed 156800 samples.\n",
      "\tProcessed 157440 samples.\n",
      "\tProcessed 158080 samples.\n",
      "\tProcessed 158720 samples.\n",
      "\tProcessed 159360 samples.\n",
      "\tProcessed 160000 samples.\n",
      "\tProcessed 160640 samples.\n",
      "\tProcessed 161280 samples.\n",
      "\tProcessed 161920 samples.\n",
      "\tProcessed 162560 samples.\n",
      "\tProcessed 163200 samples.\n",
      "\tProcessed 163840 samples.\n",
      "\tProcessed 164480 samples.\n",
      "\tProcessed 165120 samples.\n",
      "\tProcessed 165760 samples.\n",
      "\tProcessed 166400 samples.\n",
      "\tProcessed 167040 samples.\n",
      "\tProcessed 167680 samples.\n",
      "\tProcessed 168320 samples.\n",
      "\tProcessed 168960 samples.\n",
      "\tProcessed 169600 samples.\n",
      "\tProcessed 170240 samples.\n",
      "\tProcessed 170880 samples.\n",
      "\tProcessed 171520 samples.\n",
      "\tProcessed 172160 samples.\n",
      "\tProcessed 172800 samples.\n",
      "\tProcessed 173440 samples.\n",
      "\tProcessed 174080 samples.\n",
      "\tProcessed 174720 samples.\n",
      "\tProcessed 175360 samples.\n",
      "\tProcessed 176000 samples.\n",
      "\tProcessed 176640 samples.\n",
      "\tProcessed 177280 samples.\n",
      "\tProcessed 177920 samples.\n",
      "\tProcessed 178560 samples.\n",
      "\tProcessed 179200 samples.\n",
      "\tProcessed 179840 samples.\n",
      "\tProcessed 180480 samples.\n",
      "\tProcessed 181120 samples.\n",
      "\tProcessed 181760 samples.\n",
      "\tProcessed 182400 samples.\n",
      "\tProcessed 183040 samples.\n",
      "\tProcessed 183680 samples.\n",
      "\tProcessed 184320 samples.\n",
      "\tProcessed 184960 samples.\n",
      "\tProcessed 185600 samples.\n",
      "\tProcessed 186240 samples.\n",
      "\tProcessed 186880 samples.\n",
      "\tProcessed 187520 samples.\n",
      "\tProcessed 188160 samples.\n",
      "\tProcessed 188800 samples.\n",
      "\tProcessed 189440 samples.\n",
      "\tProcessed 190080 samples.\n",
      "\tProcessed 190720 samples.\n",
      "\tProcessed 191360 samples.\n",
      "\tProcessed 192000 samples.\n",
      "\tProcessed 192640 samples.\n",
      "\tProcessed 193280 samples.\n",
      "\tProcessed 193920 samples.\n",
      "\tProcessed 194560 samples.\n",
      "\tProcessed 195200 samples.\n",
      "\tProcessed 195840 samples.\n",
      "\tProcessed 196480 samples.\n",
      "\tProcessed 197120 samples.\n",
      "\tProcessed 197760 samples.\n",
      "\tProcessed 198400 samples.\n",
      "\tProcessed 199040 samples.\n",
      "\tProcessed 199680 samples.\n",
      "\n",
      "~~~~~~~~~~\n",
      "\n",
      "Total elapsed time for inference: 50.72 minutes.\n",
      "\n",
      "~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(dloader):\n",
    "        image = sample['image'].to(device) # retrieve the image chunks (unlabeled)\n",
    "        bboxes = sample['bbox']  # Get the bounding boxes for the image chunks\n",
    "\n",
    "        # Make predictions\n",
    "        output = model(image.float())\n",
    "        probabilities = softmax(output, dim=1).cpu().numpy()  # Get probabilities for all classes\n",
    "        predictions = output.argmax(dim=1).cpu().numpy() # the predicted class\n",
    "        confidence = probabilities.max(axis=1)  # max probability for the predicted class\n",
    "\n",
    "        # Assign predictions and probabilities to all footprints that intersect with the bounding box\n",
    "        batch_results = [] # store results for each chunk\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            prob_dict = {code_mapping[j]: probabilities[i, j] for j in range(n_classes)}  # Use class names as column headers\n",
    "            batch_results.append({\n",
    "                'chunk_idx': batch_idx * params['batch_size'] + i,  # Optional chunk ID\n",
    "                'bbox': bbox,  # Bounding box of the chunk\n",
    "                'prediction': code_mapping[predictions[i]],  # Map prediction to class name\n",
    "                'confidence': confidence[i],\n",
    "                **prob_dict  # Include all class probabilities with class names as column headers\n",
    "            })\n",
    "\n",
    "        batch_df = pd.DataFrame(batch_results)\n",
    "        res_df = pd.concat([res_df, batch_df], ignore_index=True)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\tProcessed {batch_idx * params['batch_size']} samples.\")\n",
    "\n",
    "        # Clear GPU memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time for inference: {t2:.2f} minutes.\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09b3a12c-eacb-4931-b264-b7fc67fe2116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>CN</th>\n",
       "      <th>AP</th>\n",
       "      <th>SL</th>\n",
       "      <th>TG</th>\n",
       "      <th>CS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((508164 4398225, 508164 4398459, 5079...</td>\n",
       "      <td>TL</td>\n",
       "      <td>0.675061</td>\n",
       "      <td>0.675061</td>\n",
       "      <td>0.182554</td>\n",
       "      <td>0.055058</td>\n",
       "      <td>0.019207</td>\n",
       "      <td>0.037738</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.019743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((508158 4395276, 508158 4395510, 5079...</td>\n",
       "      <td>WS</td>\n",
       "      <td>0.452872</td>\n",
       "      <td>0.038388</td>\n",
       "      <td>0.452872</td>\n",
       "      <td>0.307006</td>\n",
       "      <td>0.040259</td>\n",
       "      <td>0.125458</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.025328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((508143 4408032, 508143 4408266, 5079...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.999567</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.999567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((508137 4409817, 508137 4410051, 5079...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.999218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((508137 4409076, 508137 4409310, 5079...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.998226</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.998226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_idx                                               bbox prediction  \\\n",
       "0         0  POLYGON ((508164 4398225, 508164 4398459, 5079...         TL   \n",
       "1         1  POLYGON ((508158 4395276, 508158 4395510, 5079...         WS   \n",
       "2         2  POLYGON ((508143 4408032, 508143 4408266, 5079...         CS   \n",
       "3         3  POLYGON ((508137 4409817, 508137 4410051, 5079...         CS   \n",
       "4         4  POLYGON ((508137 4409076, 508137 4409310, 5079...         CS   \n",
       "\n",
       "   confidence        TL        WS        CN        AP        SL        TG  \\\n",
       "0    0.675061  0.675061  0.182554  0.055058  0.019207  0.037738  0.010638   \n",
       "1    0.452872  0.038388  0.452872  0.307006  0.040259  0.125458  0.010690   \n",
       "2    0.999567  0.000100  0.000234  0.000021  0.000023  0.000014  0.000042   \n",
       "3    0.999218  0.000141  0.000316  0.000029  0.000043  0.000024  0.000230   \n",
       "4    0.998226  0.000405  0.000597  0.000089  0.000115  0.000065  0.000504   \n",
       "\n",
       "         CS  \n",
       "0  0.019743  \n",
       "1  0.025328  \n",
       "2  0.999567  \n",
       "3  0.999218  \n",
       "4  0.998226  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e619376-4490-4140-a887-e7dde8c4779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = os.path.join(results_dir,'classification/')\n",
    "if not os.path.exists(out_fp):\n",
    "    os.makedirs(out_fp)\n",
    "out_fp = os.path.join(out_fp,'denver-resnet18-inference_ms-footprints.csv')\n",
    "res_df.to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d400536-86b7-47fe-a7b4-debe0e9e5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b2ec4c-9fb9-492a-a475-794b91bd6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663ce2d-59f5-4ab6-80a0-f5d07edd045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4460219c-5b77-45c4-ad22-412066666418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>CN</th>\n",
       "      <th>AP</th>\n",
       "      <th>SL</th>\n",
       "      <th>TG</th>\n",
       "      <th>CS</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TL</td>\n",
       "      <td>0.600086</td>\n",
       "      <td>0.318447</td>\n",
       "      <td>0.367123</td>\n",
       "      <td>0.050103</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>0.037375</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.197460</td>\n",
       "      <td>POLYGON ((508060.415 4398334.066, 508060.659 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CN</td>\n",
       "      <td>0.506891</td>\n",
       "      <td>0.059596</td>\n",
       "      <td>0.242447</td>\n",
       "      <td>0.318632</td>\n",
       "      <td>0.030853</td>\n",
       "      <td>0.093931</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.243266</td>\n",
       "      <td>POLYGON ((508048.832 4395402.828, 508034.603 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.996183</td>\n",
       "      <td>POLYGON ((508035.125 4408152.316, 508022.631 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>POLYGON ((508027.602 4409939.978, 508015.196 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>POLYGON ((508026.68 4409187.594, 508026.841 44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid prediction  confidence        TL        WS        CN        AP  \\\n",
       "0    1         TL    0.600086  0.318447  0.367123  0.050103  0.017146   \n",
       "1    2         CN    0.506891  0.059596  0.242447  0.318632  0.030853   \n",
       "2    3         CS    0.996183  0.000535  0.000808  0.000123  0.000160   \n",
       "3    4         CS    0.999402  0.000131  0.000328  0.000021  0.000023   \n",
       "4    5         CS    0.998353  0.000330  0.000572  0.000062  0.000167   \n",
       "\n",
       "         SL        TG        CS  \\\n",
       "0  0.037375  0.012347  0.197460   \n",
       "1  0.093931  0.011274  0.243266   \n",
       "2  0.000094  0.002096  0.996183   \n",
       "3  0.000017  0.000078  0.999402   \n",
       "4  0.000047  0.000470  0.998353   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((508060.415 4398334.066, 508060.659 4...  \n",
       "1  POLYGON ((508048.832 4395402.828, 508034.603 4...  \n",
       "2  POLYGON ((508035.125 4408152.316, 508022.631 4...  \n",
       "3  POLYGON ((508027.602 4409939.978, 508015.196 4...  \n",
       "4  POLYGON ((508026.68 4409187.594, 508026.841 44...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a GeoDataFrame\n",
    "res_gdf = gpd.GeoDataFrame(res_df, geometry=res_df['bbox'], crs=footprints.crs)\n",
    "\n",
    "# Perform a spatial join to the footprints\n",
    "res_gdf_footprints = gpd.sjoin(footprints, res_gdf, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Group by footprint UID and calculate the mean of probabilities for overlapping chunks\n",
    "agg_dict = {class_name: 'mean' for class_name in class_labels}\n",
    "agg_dict.update({\n",
    "    'confidence': 'mean',  # Calculate mean confidence\n",
    "    'prediction': lambda x: x.mode()[0]  # Use the most common prediction (mode)\n",
    "})\n",
    "\n",
    "# Aggregate by footprint ID\n",
    "agg_results = res_gdf_footprints.groupby('uid').agg(agg_dict).reset_index()\n",
    "# Merge back to the original footprint data\n",
    "inference_results = footprints.merge(agg_results, on='uid', how='left')\n",
    "inference_results = inference_results[['uid','prediction','confidence']+class_labels+['geometry']] \t\n",
    "\n",
    "inference_results.to_file(os.path.join(results_dir, 'denver-resnet18-inference_ms-footprints_mean.gpkg'), driver='GPKG')\n",
    "inference_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60129f0f-7d51-45b3-959a-1105e6f66aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bdb3d-f72e-468a-8141-0be069af885e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82c7813e-bd07-4426-b399-b8a83e3e360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
