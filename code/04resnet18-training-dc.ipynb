{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a157a0-0b7e-4a0d-900c-79bc0fc3d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6dba8-e355-492b-b096-59ff723e68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resnet-18 for classifying roof materials from PlanetScope SuperDove imagery\n",
    "Case study in Washington, D.C. \n",
    "\"\"\"\n",
    "\n",
    "import os, sys, time, glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms, utils\n",
    "from torchsat.models.classification import resnet18\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import box\n",
    "from os.path import join\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Custom functions\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "# Projection information\n",
    "wgs = from_epsg(4326)\n",
    "proj = from_epsg(32618)\n",
    "print(f'Projected CRS: {proj}')\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "\n",
    "print(\"Successfully imported all packages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce3bf8-31c5-456f-a965-3c7bc461ab09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698eaec-2a8f-44a9-af31-656cf38de292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f0db2-184a-4589-b258-7283e30f23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "homedir = '/home/jovyan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d53102-f55f-43ae-a20d-3bf28ce5de9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308774c2-5428-4247-adb3-836626ae7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (footprints)\n",
    "# gdf_path = os.path.join(maindir,'data/spatial/mod/dc_data/training/dc_data_reference_footprints.gpkg')\n",
    "gdf_path = join(homedir,'opp-data/dc_data_reference_footprints.gpkg')\n",
    "ref = gpd.read_file(gdf_path)\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f1d04-70ba-48da-91fe-4ecd358ca528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the class imbalance\n",
    "ref.class_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfad719-f3c2-48df-aa52-66ee519b11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric code column\n",
    "ref['code'], _ = pd.factorize(ref['class_code'])\n",
    "# Create a dictionary mapping class_code to code\n",
    "code_mapping = dict(zip(ref['class_code'], ref['code']))\n",
    "desc_mapping = dict(zip(ref['class_code'], ref['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94802aed-11a3-4285-952e-8409b5ff2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the longest side length of the building\n",
    "area_stats = ref.groupby('class_code').apply(footprint_area_stats).reset_index()\n",
    "area_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3f633-3a27-472d-ba32-4248eb2032c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot for mean footprint area across classes\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.boxplot(x='class_code', y='areaUTMsqft', data=ref)\n",
    "# Set the y-axis to log scale\n",
    "plt.yscale('log')\n",
    "plt.title('Average Footprint Area Across Classes (Log Scale)')\n",
    "plt.ylabel('Mean Area (sqm)')\n",
    "plt.xlabel('Building Class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c523f1-01fe-46b4-8ec6-54f3bc3dc2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the longest side length for polygons\n",
    "ref['longest_side_len'] = ref.geometry.apply(lambda geom: calc_longest_side(geom)[2])\n",
    "\n",
    "# Box plot for mean footprint area across classes\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.boxplot(x='class_code', y='longest_side_len', data=ref)\n",
    "# Set the y-axis to log scale\n",
    "plt.yscale('log')\n",
    "plt.title('Longest Side Length Across Classes')\n",
    "plt.ylabel('Length (m)')\n",
    "plt.xlabel('Building Class')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694bde40-f92c-46ad-bce3-6b40075e4b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f5979-0193-46e0-ab26-1e7449d2714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify 'pure-ish' training locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399a7ff-e031-4056-9f93-53292e95b5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c94b42-ea39-4726-abd2-6cfa775b636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d1851-bb0c-4bdd-bc8a-e41414f47d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c96b1-7be7-4baa-9584-6e19c28e41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create centroids\n",
    "# ref_pt = ref.copy()\n",
    "# ref_pt = ref_pt.to_crs(epsg=32618)\n",
    "# ref_pt['geometry'] = ref_pt['geometry'].centroid\n",
    "\n",
    "# # Define the window size and half window (for boxes)\n",
    "# window_size = 52 # 4 * average side length (relative neighbors (?))\n",
    "# half_window = window_size / 2\n",
    "\n",
    "# training_windows = [] # image windows with >50% of specific roof type\n",
    "# training_roof_types = [] # roof type codes for valid windows\n",
    "\n",
    "# # Loop through each footprint individually\n",
    "# for geom, roof_type in zip(ref.geometry, ref['class_code']):\n",
    "#     # calculate the image window as footprint buffer\n",
    "#     centroid = geom.centroid\n",
    "#     window = box(centroid.x - half_window, centroid.y - half_window,\n",
    "#                  centroid.x + half_window, centroid.y + half_window)\n",
    "\n",
    "#     # Intersect with centroids to get class count within window\n",
    "#     intersect = ref_pt[ref_pt.intersects(window)]\n",
    "    \n",
    "#     # Get the total count and count for the class\n",
    "#     total_count = len(intersect)\n",
    "#     class_count = len(intersect[intersect['class_code'] == roof_type])\n",
    "\n",
    "#     # Check if there is at least 50% of the roof type in that window\n",
    "#     if total_count > 0 and (class_count / total_count) > 0.50:\n",
    "#         training_windows.append(geom)\n",
    "#         training_roof_types.append(roof_type)\n",
    "\n",
    "#     del intersect, window, centroid\n",
    "\n",
    "# # Create a GeoDataFrame for the training windows with roof types\n",
    "# ref_windows = gpd.GeoDataFrame({\n",
    "#     'geometry': training_windows, \n",
    "#     'class_code': training_roof_types\n",
    "# }, crs=ref.crs)\n",
    "\n",
    "# # Create a numeric code for the training data frame\n",
    "# ref_windows['code'], _ = pd.factorize(ref_windows['class_code'])\n",
    "# print(\"Spatial filtering complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf332f4-7848-47f2-8a23-784101265939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save out\n",
    "# os.getcwd()\n",
    "# out_file = os.path.join(maindir,'data/spatial/mod/dc_data/rooftop_materials_training_windows.gpkg')\n",
    "# ref_windows.to_file(out_file)\n",
    "\n",
    "# del training_windows, training_roof_types, ref_pt\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edde283-208e-4368-ad7b-92c4c2ad097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the training locations with colors based on roof type\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# ref_windows.plot(column='class_code', ax=ax, legend=True, cmap='Set1', edgecolor='none')\n",
    "# plt.title('Training Locations by Roof Material Type')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a09fb4-3432-4cb6-9de6-89728c147413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_windows.class_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195a3a1-e907-4f3e-87a4-ce28d6001e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform balanced sampling (random undersampling)\n",
    "# ref_bal = balance_sampling(ref_windows, ratio=20, strategy='undersample')\n",
    "# ref_bal.class_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e07b5-4cb5-4c75-9bd8-33305bd6406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform balanced sampling (random undersampling)\n",
    "ref_bal = balance_sampling(ref, ratio=10, strategy='undersample')\n",
    "ref_bal.class_code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4483537-a9f9-4008-b8e0-049dc6d924e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124813b-03f5-4a1f-8db0-269f000739e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d138d-4766-407b-8d08-0bedbcd88db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df331a-d7e5-401c-8077-f5e2053039c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train/test data\n",
    "train_df, val_df, test_df = split_training_data(ref_bal, ts=0.4, vs=0.2)\n",
    "\n",
    "# Print the class distribution in training and validation sets to verify stratification\n",
    "print(\"Train class distribution:\\n\", train_df['code'].value_counts())\n",
    "print(\"Validation class distribution:\\n\", val_df['code'].value_counts())\n",
    "print(\"Test class distribution:\\n\", test_df['code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef573cf-7e7b-4af7-8eb9-b998403b5716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21eaab-8a6f-4361-9356-9fbbd2ff3ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff13cc3-7121-4e88-8392-f25c83a7f9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca50c71-761b-48d5-95ca-e23731769ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our image data to check on the format\n",
    "# stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da_fp = os.path.join(homedir,'opp-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfdcfd-1319-445a-92c9-faf298c8d4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055ca12-c480-447d-b01d-8efc157e579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 128, 'learning_rate': 0.001, 'weight_decay': 1e-4, 'momentum': 0.9, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d7160-f87e-4c9e-903b-44c966444fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d0cb6-dcd0-424a-a68e-96abf0819354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Resnet-18 model\n",
    "\n",
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model dev ...')\n",
    "\n",
    "# Grab the number of classes\n",
    "n_classes = ref_bal.class_code.unique().shape[0]\n",
    "print(f'There are {n_classes} roof type classes.')\n",
    "\n",
    "# Define the Resnet-18 model (in_channels = number of bands in the image)\n",
    "model = resnet18(n_classes, in_channels=n_bands, pretrained=False)\n",
    "\n",
    "# Make model parallel and on GPU\n",
    "if torch.cuda.device_count() >= 1:\n",
    "    print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "else:\n",
    "    model = nn.DataParallel(model)\n",
    "    print('Made cpu parallel')\n",
    "\n",
    "# optimizer, learning rate scheduler, loss criterion, scaler (gradient)\n",
    "optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=params['momentum'], weight_decay=params['weight_decay'])\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=params['patience'], verbose=False, min_lr=1e-6)\n",
    "scaler = torch.cuda.amp.GradScaler()  # initialize scaler for mixed precision\n",
    "\n",
    "print('Ready to load data !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d179c-0bd8-4ca3-9de8-a679e9537406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image data as a Dataset\n",
    "# Uses the opimum window size calculated earlier\n",
    "\n",
    "imdir = stack_da_fp\n",
    "bs = params['batch_size']\n",
    "window_size = params['window_size']\n",
    "\n",
    "pin_memory=False\n",
    "if device == \"cuda\":\n",
    "    pin_memory=True # for GPU make true\n",
    "\n",
    "# Create the training samples\n",
    "train_ds = RoofImageDatasetPlanet(train_df[['geometry', 'code']], imdir, n_bands=n_bands, img_dim=window_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, num_workers=0, shuffle=True, pin_memory=pin_memory) \n",
    "\n",
    "# Create the validation samples\n",
    "val_ds = RoofImageDatasetPlanet(val_df[['geometry', 'code']], imdir, n_bands=n_bands, img_dim=window_size)\n",
    "val_loader = DataLoader(val_ds, batch_size=bs * 2, num_workers=0, shuffle=False, pin_memory=pin_memory)\n",
    "\n",
    "# Create the test samples\n",
    "test_ds = RoofImageDatasetPlanet(test_df[['geometry', 'code']], imdir, n_bands=n_bands, img_dim=window_size)\n",
    "test_loader = DataLoader(test_ds, batch_size=bs * 2, num_workers=0, shuffle=False, pin_memory=pin_memory)\n",
    "\n",
    "print(\"Training and validation data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d575af0-fe24-43f0-96b7-467d5475c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples in each class\n",
    "val_counts = list(train_df['code'].value_counts())\n",
    "total_samples = sum(val_counts) # total number of samples\n",
    "print(f'Total samples: {total_samples};\\nValue counts: {val_counts}')\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = [total_samples / count for count in val_counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "class_weights_norm = class_weights / class_weights.sum()\n",
    "print(f\"Normalized class weights: {class_weights_norm}\")\n",
    "\n",
    "# Updated loss function with weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_norm).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9c1a4-3107-4970-816e-c9a122ddeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350d162-f79d-48fd-a362-34c4982aefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "print_freq = int(len(train_loader) // 4) # quarterly print statements\n",
    "\n",
    "# Initialize lists to track the losses for each epoch\n",
    "train_losses = [] # stores epoch train losses\n",
    "val_losses = [] # stores epoch validation losses\n",
    "\n",
    "num_epochs = 22 # adjust as needed\n",
    "for epoch in range(1, num_epochs):\n",
    "    t00 = time.time() # epoch start time\n",
    "\n",
    "    # The current learning rate:\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch [{epoch}]. Current learning rate: {current_lr}\")\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "\n",
    "    batch_train_losses = [] # to store the loss/batch\n",
    "    \n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        # Ensure a good batch\n",
    "        batch = make_good_batch(batch)\n",
    "        \n",
    "        # Extract samples (image chunk, target label)\n",
    "        image, target = batch['image'].to(device), batch['code'].to(device)\n",
    "\n",
    "        optimizer.zero_grad() # reset the gradient\n",
    "\n",
    "        # Use mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(image.float())\n",
    "            loss = criterion(output, target.long())\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed precision backward pass\n",
    "        scaler.step(optimizer)  # Optimizer step\n",
    "        scaler.update()\n",
    "\n",
    "        # Print the train progress % and current loss\n",
    "        if idx % print_freq == 0:\n",
    "            print(f'\\ttrain progress: [{idx * len(image)}/{len(train_loader.dataset)}] ({(100. * idx / len(train_loader)):.2f})%')\n",
    "            print(f'\\tbatch train loss: {loss.item():.4f};\\tcumulative batch: {len(train_loader) * epoch + idx}')\n",
    "        \n",
    "        batch_train_losses.append((idx, loss.item())) # append to batch losses list\n",
    "\n",
    "        del image, target, batch, output, loss\n",
    "                \n",
    "    # average loss for the epoch (across batches)\n",
    "    train_loss = np.array(batch_train_losses)[:,1].mean()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # validation loss\n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    all_labs = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            # Ensure a good batch\n",
    "            batch = make_good_batch(batch) \n",
    "            \n",
    "            # Extract samples\n",
    "            image, target = batch['image'].to(device), batch['code'].to(device)\n",
    "            output = model(image.float())\n",
    "\n",
    "            # Get validation loss and predictions\n",
    "            val_loss += criterion(output, target).item()\n",
    "            predicted = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += predicted.eq(target.view_as(predicted)).sum().item() # Number of correct\n",
    "            \n",
    "            # Store the labels\n",
    "            all_labs.extend(target.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "            del image, target, batch, output\n",
    "            \n",
    "        val_loss /= len(val_loader.dataset)/val_loader.batch_size\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(f\"\\nEpoch [{epoch}] completed.\")\n",
    "    print(f'\\ttrain loss: {train_loss}; validation loss = {val_loss:.4f}')\n",
    "\n",
    "    acc = 100. * correct / len(val_loader.dataset)\n",
    "    f1 = f1_score(all_labs, all_preds, average=\"weighted\")\n",
    "    print(f'\\tAccuracy (validation): [{correct}/{len(val_loader.dataset)}] ({acc:.4f})%;\\n\\tF1-score (validation): {f1:.4f}')\n",
    "\n",
    "    # Adjust the learning rate based on the validation loss\n",
    "    lr_scheduler.step(val_loss)\n",
    "    if optimizer.param_groups[0]['lr'] != current_lr:\n",
    "        print(f\"! LR-Scheduler [ReduceLROnPlateau] adjustment: {optimizer.param_groups[0]['lr']} !\")\n",
    "     \n",
    "    t1 = (time.time() - t00) / 60\n",
    "    print(f\"Time to complete epoch [{epoch}]: {t1:.2f} minutes.\")\n",
    "    print(\"\\n~~~~~~~~~~\\n\")\n",
    "\n",
    "    # # (optional) Implement early stopping based on 'patience'\n",
    "    # if val_loss < best_val_loss:\n",
    "    #     best_val_loss = val_loss\n",
    "    #     counter = 0  # Reset counter if we see an improvement\n",
    "    # else:\n",
    "    #     counter += 1  # Increment counter if no improvement after learning rate adjustment\n",
    "    #     if counter >= params['patience'] + 2:\n",
    "    #         print(f\"Early stopping after [{epoch}] epochs.\")\n",
    "    #         break\n",
    "    \n",
    "    gc.collect() # do a garbage cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time: {t2:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d0fc8-11b3-4ae8-9771-2ce256d4dc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad061561-38d0-428b-80f2-8a07c8fc7f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5366e-7979-4602-bde3-05c216c3d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model loss function\n",
    "plt.plot(np.array(losses)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5270f143-d978-48dd-b467-d05bd7cb0c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch training loss\n",
    "plt.plot(epoch_losses, label='epoch training loss')\n",
    "plt.plot(val_losses, label='epoch validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242b8aa-59fd-4eef-98e4-762e40b4740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134768f5-2fa4-4f3e-ba77-ada188abbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "# results directory\n",
    "save_dir = os.path.join(maindir,'results/resnet18/')\n",
    "roi = 'dc'\n",
    "\n",
    "save_res = True\n",
    "if save_res:\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # save the model\n",
    "    step = len(losses)\n",
    "    model_path = f'{roi}_planet_ms_ws{params['window_size']}_bs{params['batch_size']}_lr{params['learning_rate']}_ep{num_epochs}_step{step}.pt'\n",
    "    model_path = os.path.join(save_dir, model_path)\n",
    "    save = lambda ep: torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'step': step,\n",
    "        }, str(model_path))\n",
    "\n",
    "    save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73166d-02a0-4a12-a988-9149467ff2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(save_dir, 'losses_ep{}_step{}_b{}.txt'.format(num_epochs, step, bs)), np.array(losses))\n",
    "np.savetxt(os.path.join(save_dir, 'epoch_loss_ep{}_step{}_b{}.txt'.format(num_epochs, step, bs)), np.array(epoch_loss))\n",
    "np.savetxt(os.path.join(save_dir, 'val_losses_ep{}_step{}_b{}.txt'.format(num_epochs, step, bs)), np.array(val_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554d2e0-c1e1-4a85-b09e-990a82f7df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def get_prediction(m, s):\n",
    "    s = s.to(device)  # Ensure the sample is moved to the correct device\n",
    "    res = m(s)\n",
    "    return res\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "for idx, sample in enumerate(test_ds):\n",
    "    try:\n",
    "        if sample['code'] != 255:\n",
    "            # Append true labels\n",
    "            true_labels.append(sample['code'].item())  # Convert tensor to Python scalar\n",
    "                        \n",
    "            # Get prediction and append\n",
    "            pred = get_prediction(model, sample['image'][None, ...].float().to(device))  # Ensure tensor is float and on the correct device\n",
    "            pred_labels.append(pred.argmax().item())  # Convert tensor to Python scalar\n",
    "            \n",
    "        else:\n",
    "            print(f'sample {idx} of {len(test_ds)} had class label 255, skipping...')\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            time.sleep(0.3)\n",
    "            gc.collect()\n",
    "            print(f'Processed {idx} samples...')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'Error at sample {idx}: {e}, continuing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dba4d1-565e-4e0a-ad67-0eaa092ff625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'class_code' is of categorical dtype\n",
    "test_df['code'] = test_df['code'].astype('category')\n",
    "\n",
    "# Create the dictionary mapping\n",
    "cat_dict = dict(enumerate(test_df['code'].cat.categories))\n",
    "print(cat_dict)\n",
    "\n",
    "# Filter the class codes present in the test set\n",
    "class_codes_numbers = [k for k in cat_dict.keys() if cat_dict[k] in test_df['code'].unique().tolist()]\n",
    "\n",
    "cor_labels = [cat_dict[c] for c in class_codes_numbers]\n",
    "print(cor_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb19cec-362a-4f0c-85c1-510cd791d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00bbb05-a44c-46c5-8e19-c3772b90bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad) # number of trainable model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27edc2c6-16d6-470a-aa54-ba97d9812f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report\n",
    "cr_df = pd.DataFrame(classification_report(true_labels, pred_labels, target_names=cor_labels, output_dict=True)).transpose()\n",
    "print(cr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c694f93-77ad-4f62-9376-2187a428f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cor_labels:\n",
    "    print(test_df.loc[test_df['code'] == c].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a222edf-19dc-4873-9aa2-c58f41497d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_names = cor_labels # get these smartly somehow... categories got a bit mixed up\n",
    "class_labels = class_codes_numbers\n",
    "cm = confusion_matrix(true_labels, pred_labels, labels=cor_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=cor_labels)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
