{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a157a0-0b7e-4a0d-900c-79bc0fc3d0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 16 09:41:49 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070        Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   36C    P8               5W / 185W |    264MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ae6dba8-e355-492b-b096-59ff723e68cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Resnet-18 for classifying roof materials from PlanetScope SuperDove imagery\n",
    "Case study in Washington, D.C. \n",
    "\"\"\"\n",
    "\n",
    "import os, time, glob\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import transforms, utils\n",
    "from torchsat.models.classification import resnet18\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from fiona.crs import from_epsg\n",
    "from shapely.geometry import box\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion() # interactive\n",
    "\n",
    "# Projection information\n",
    "wgs = from_epsg(4326)\n",
    "proj = from_epsg(32618)\n",
    "print(f'Projected CRS: {proj}')\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "\n",
    "print(\"Successfully imported all packages!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2ce3bf8-31c5-456f-a965-3c7bc461ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class and functions ready to use!\n"
     ]
    }
   ],
   "source": [
    "class RoofImageDataset_Planet(Dataset):\n",
    "    \"\"\"Class to handle PlanetScope SuperDove imagery for Resnet-18\"\"\"\n",
    "\n",
    "    def __init__(self, gdf, img_path, n_bands=8, imgdim=64, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gdf: Geodataframe containing 'geometry' column and 'class_code' column\n",
    "            img_path: the path to the PlanetScope SuperDove composite image (single mosaic file)\n",
    "                - see 'psscene-prep.py' for spectral indices calculation\n",
    "            imgdim (int): Image dimension for CNN implementation\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "\n",
    "        Returns image chunks with class labels\n",
    "        \"\"\"\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            raise ValueError(f'Image does not exists: {img_path}')\n",
    "\n",
    "        self.geometries = [p.centroid for p in gdf.geometry.values]\n",
    "        self.img = img_path\n",
    "        self.image_dim = imgdim # resnet window dimension, defaults to 64\n",
    "        self.n_bands = n_bands\n",
    "        self.Y = gdf.code.values\n",
    "        # Define transforms\n",
    "        if transform is not None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((self.image_dim, self.image_dim)),  # Resize to NxN for ResNet-18\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.geometries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Sample the PlanetScope image\n",
    "        left, bottom, right, top = self.geometries[idx].bounds\n",
    "        geom = self.geometries[idx]\n",
    "\n",
    "        try:\n",
    "            sample = self.sample_image(geom)  # run the sampling function\n",
    "            \n",
    "            # if self.transform:\n",
    "            #     sample = self.transform(sample)  # transform to common size\n",
    "\n",
    "            cc = self.Y[idx]  # get the class codes\n",
    "            \n",
    "            # Ensure the sample has the correct dimensions\n",
    "            if sample.shape[1:] != (self.image_dim, self.image_dim):\n",
    "                raise ValueError(f'Invalid sample shape: {sample.shape}')\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping invalid sample at index {idx}: {e}\")\n",
    "            return None  # Return None for invalid samples\n",
    "        \n",
    "        # Convert the sample array to a Torch object\n",
    "        sample = torch.from_numpy(sample)\n",
    "\n",
    "        return {'image': sample.type(torch.FloatTensor),\n",
    "                'code': torch.tensor(cc).type(torch.LongTensor)}\n",
    "        \n",
    "        \n",
    "    def sample_image(self, geom):\n",
    "        # Sample the image at each geometry\n",
    "        samples = [] # store the samples in a list\n",
    "\n",
    "        N = self.image_dim\n",
    "        half_N = self.image_dim / 2\n",
    "            \n",
    "        # Use the windows.from_bounds() method to return the window\n",
    "        # Returns image chunks from training data locations\n",
    "        with rio.open(self.img) as src:\n",
    "            py, px = src.index(geom.x, geom.y)\n",
    "            window = rio.windows.Window(px - N // 2, py - N // 2, N, N)\n",
    "            \n",
    "            # Read the data in the window\n",
    "            # clip is a nbands * N * N numpy array\n",
    "            clip = src.read(window=window)\n",
    "\n",
    "            # Handle the case where the sample is smaller than the expected size\n",
    "            if clip.shape != (self.n_bands, N, N):\n",
    "                raise ValueError(f'Invalid sample shape: {clip.shape}\\nAttempting to create padding ...')\n",
    "                padding = [(0, 0), (0, max(0, N - clip.shape[1])), (0, max(0, N - clip.shape[2]))]\n",
    "                clip = np.pad(clip, padding, mode='constant', constant_values=0)\n",
    "            else:\n",
    "                samples.append(clip)\n",
    "\n",
    "            del clip, py, px, window\n",
    "\n",
    "        # Convert the image chunk to a numpy array\n",
    "        samples_arr = np.array(samples)\n",
    "\n",
    "        del samples # Clear up memory\n",
    "\n",
    "        # Make sure there is valid data\n",
    "        if samples_arr.sum() > 0:\n",
    "            ans = np.ma.masked_equal(samples_arr, 0).mean(axis=0)\n",
    "        else:\n",
    "            ans = samples_arr.mean(axis=0)\n",
    "\n",
    "        del samples_arr\n",
    "\n",
    "        return ans\n",
    "\n",
    "\n",
    "def make_good_batch(batch):\n",
    "    \"\"\"\n",
    "    Removes bad samples if image dimensions do not match.\n",
    "    Args:\n",
    "        - batch: list of dictionaries, each containing 'image' tensor and 'code' tensor\n",
    "    returns: list of dictionaries same as input with samples having non-matching image dims removed\n",
    "    \"\"\"\n",
    "    valid_samples = []\n",
    "    for sample in batch:\n",
    "        if sample is not None:\n",
    "            image, code = sample['image'], sample['code']\n",
    "            if code != 255 and not torch.isnan(code) and not torch.isinf(code):\n",
    "                if not torch.isnan(image).any() and not torch.isinf(image).any():\n",
    "                    if image.shape == (8, 64, 64):  # Ensure dimensions match\n",
    "                        valid_samples.append(sample)\n",
    "            del image, code\n",
    "\n",
    "    if not valid_samples:\n",
    "        return None\n",
    "\n",
    "    return default_collate(valid_samples)\n",
    "    del valid_samples, sample\n",
    "\n",
    "\n",
    "def balance_sampling(df, ratio=1, strategy='undersample'):\n",
    "    \"\"\"\n",
    "    Generate balanced sample from training data based on the given ratio.\n",
    "    \"\"\"\n",
    "    # Get the class counts\n",
    "    class_counts = df['class_code'].value_counts()\n",
    "    min_class_count = class_counts.min()\n",
    "    # Calculate the target count for each class based on the ratio\n",
    "    target_count = {class_label: min(min_class_count * ratio, len(df[df['class_code'] == class_label]))\n",
    "                    for class_label in class_counts.index}\n",
    "    # Create an empty list to store balanced dataframes\n",
    "    balanced_dfs = []\n",
    "    for class_label in class_counts.index:\n",
    "        class_df = df[df['class_code'] == class_label]\n",
    "        if strategy == 'undersample':\n",
    "            # Under-sample the majority class\n",
    "            balanced_class_df = resample(\n",
    "                class_df, replace=False, n_samples=target_count[class_label], random_state=42)\n",
    "        elif strategy == 'oversample':\n",
    "            # Over-sample the minority class\n",
    "            balanced_class_df = resample(\n",
    "                class_df, replace=True, n_samples=target_count[class_label], random_state=42)\n",
    "        balanced_dfs.append(balanced_class_df)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs)\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "print(\"Class and functions ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577f0a05-5aed-4233-a6f5-c06462bae509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73acf7f-7546-4aa7-880c-489596ef92dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f6824-7a2c-4d67-913e-3714fc33e5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e64b5e6b-0538-4cc5-8bad-d44631916569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/jovyan')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308774c2-5428-4247-adb3-836626ae7255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_code</th>\n",
       "      <th>areaUTMsqft</th>\n",
       "      <th>uid</th>\n",
       "      <th>description</th>\n",
       "      <th>code</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS</td>\n",
       "      <td>357.783709</td>\n",
       "      <td>1CS</td>\n",
       "      <td>Composition Shingle</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((324215.868 4313568.665, 324215.792 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS</td>\n",
       "      <td>918.640862</td>\n",
       "      <td>2CS</td>\n",
       "      <td>Composition Shingle</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((324602.816 4311717.247, 324604.322 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS</td>\n",
       "      <td>1383.414170</td>\n",
       "      <td>3CS</td>\n",
       "      <td>Composition Shingle</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((327253.581 4300371.859, 327258.154 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS</td>\n",
       "      <td>836.410297</td>\n",
       "      <td>4CS</td>\n",
       "      <td>Composition Shingle</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((333608.13 4306267.691, 333607.957 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS</td>\n",
       "      <td>330.514264</td>\n",
       "      <td>5CS</td>\n",
       "      <td>Composition Shingle</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((326482.699 4300939.466, 326487.386 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_code  areaUTMsqft  uid          description  code  \\\n",
       "0         CS   357.783709  1CS  Composition Shingle     0   \n",
       "1         CS   918.640862  2CS  Composition Shingle     0   \n",
       "2         CS  1383.414170  3CS  Composition Shingle     0   \n",
       "3         CS   836.410297  4CS  Composition Shingle     0   \n",
       "4         CS   330.514264  5CS  Composition Shingle     0   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((324215.868 4313568.665, 324215.792 4...  \n",
       "1  POLYGON ((324602.816 4311717.247, 324604.322 4...  \n",
       "2  POLYGON ((327253.581 4300371.859, 327258.154 4...  \n",
       "3  POLYGON ((333608.13 4306267.691, 333607.957 43...  \n",
       "4  POLYGON ((326482.699 4300939.466, 326487.386 4...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data (footprints)\n",
    "ref_path = os.path.join('opp/data/dc_data_reference_footprints.gpkg')\n",
    "ref = gpd.read_file(ref_path)\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f3f633-3a27-472d-ba32-4248eb2032c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean footprint area (sqm): 99.499113\n",
      "90th percentile footprint area (sqm): 158.13312473978425\n",
      "90th percentile side length (m): 12\n",
      "Potential optimal window size: 36\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 'optimal' window size from the footprint areas\n",
    "mean_area_sqm = int(ref.areaUTMsqft.values.mean()) * 0.092903\n",
    "pct90_area_sqm = np.percentile(ref.areaUTMsqft, 90) * 0.092903\n",
    "print(f'Mean footprint area (sqm): {mean_area_sqm}')\n",
    "print(f'90th percentile footprint area (sqm): {pct90_area_sqm}')\n",
    "# Calculate the side length ('optimal' window size) * 3 \n",
    "print(f'90th percentile side length (m): {int(np.sqrt(pct90_area_sqm))}')\n",
    "window_size = (int(np.sqrt(pct90_area_sqm) * 3) - 1)\n",
    "print(f'Potential optimal window size: {window_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb845358-d7eb-4350-89fd-5ae7dbbc2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "\n",
      "class_code\n",
      "ME    29651\n",
      "CS    27687\n",
      "SL    11080\n",
      "UR     1018\n",
      "WS      866\n",
      "TL      617\n",
      "SH      589\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Observe the class imbalance in the reference data\n",
    "print(f\"Class counts:\\n\\n{ref.class_code.value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a8917-595a-4e7b-9934-bf5ca4542e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f18afdd2-df96-4bc6-8b64-c445134f787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_code\n",
      "ME     29651\n",
      "CS     27687\n",
      "SL     11080\n",
      "WSH     1455\n",
      "UR      1018\n",
      "TL       617\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge the shingle classes (wood shingle and shingle)\n",
    "merge = {'WS': 'WSH', 'SH': 'WSH'}\n",
    "ref['class_code'].replace(merge, inplace=True)\n",
    "ref['code'], _ = pd.factorize(ref['class_code']) # create a factorized version\n",
    "print(ref['class_code'].value_counts())  # check the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d010599-d2fb-462f-9741-5b2bb9baa79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b030b0e8-3624-4946-8227-09db94678667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CS': 0, 'ME': 1, 'SL': 2, 'UR': 3, 'TL': 4, 'WSH': 5}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping class_code to code\n",
    "class_mapping = dict(zip(ref['class_code'], ref['code']))\n",
    "print(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092af89-47c4-4691-911f-7f468518d146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f55055-37f9-4faa-a915-731b49e56330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code\n",
       "1    6170\n",
       "0    6170\n",
       "2    6170\n",
       "5    1455\n",
       "3    1018\n",
       "4     617\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform balanced sampling (random undersampling)\n",
    "ref_bal = balance_sampling(ref, ratio=10, strategy='undersample')\n",
    "ref_bal.code.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7758d-b7b0-4642-88e1-f70b94f25552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3a0e89-b7d6-4fb2-8a39-ee3bfba17681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59df331a-d7e5-401c-8077-f5e2053039c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " code\n",
      "0    4936\n",
      "1    4936\n",
      "2    4936\n",
      "5    1164\n",
      "3     814\n",
      "4     494\n",
      "Name: count, dtype: int64\n",
      "Validation class distribution:\n",
      " code\n",
      "2    1234\n",
      "1    1234\n",
      "0    1234\n",
      "5     291\n",
      "3     204\n",
      "4     123\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split into train/test for each class\n",
    "train_df, test_df, val_df = [], [], []\n",
    "\n",
    "# Define split ratio\n",
    "vs = 0.2  # Validation size ratio (20%)\n",
    "\n",
    "# Perform stratified split to separate training data from validation data\n",
    "train_df, val_df = train_test_split(\n",
    "    ref_bal, # your filtered samples\n",
    "    test_size=vs, \n",
    "    random_state=27, \n",
    "    stratify=ref_bal['code']\n",
    ")\n",
    "\n",
    "# Print the class distribution in training and validation sets to verify stratification\n",
    "print(\"Train class distribution:\\n\", train_df['code'].value_counts())\n",
    "print(\"Validation class distribution:\\n\", val_df['code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ea955-ccd5-47ab-a6ef-9804207cbb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c8c5d-baea-4af6-8268-8eb2761d9b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd122a-1ab3-425c-9390-4aca8b23f26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca50c71-761b-48d5-95ca-e23731769ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7555, 6046)\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (316269.0, 4295631.0, 334407.0, 4318296.0)\n",
      "sum: 4.670212268829346\n",
      "CRS: EPSG:32618\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 8, y: 7555, x: 6046)> Size: 1GB\n",
      "[365420240 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 64B 1 2 3 4 5 6 7 8\n",
      "  * x            (x) float64 48kB 3.163e+05 3.163e+05 ... 3.344e+05 3.344e+05\n",
      "  * y            (y) float64 60kB 4.318e+06 4.318e+06 ... 4.296e+06 4.296e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    TIFFTAG_IMAGEDESCRIPTION:  {\"atmospheric_correction\": {\"aerosol_model\": \"...\n",
      "    TIFFTAG_DATETIME:          2022:06:05 14:56:31\n",
      "    STATISTICS_APPROXIMATE:    YES\n",
      "    STATISTICS_MAXIMUM:        15203\n",
      "    STATISTICS_MEAN:           662.44066810447\n",
      "    STATISTICS_MINIMUM:        80\n",
      "    STATISTICS_STDDEV:         475.12461911944\n",
      "    STATISTICS_VALID_PERCENT:  42.96\n",
      "    AREA_OR_POINT:             Area\n",
      "    scale_factor:              1.0\n",
      "    add_offset:                0.0\n",
      "    long_name:                 ('nir', 'ndre', 'vgnir', 'vrnir', 'ndbibg', 'n...\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "stack_da_fp = os.path.join('opp/data/dc_data_psscene15b_norm_r.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225acc4-3619-4a3e-8b58-ec80b7c69f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2464a06e-7e88-49d1-a9d7-8f55e36ee544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for model dev ...\n",
      "There are 6 roof type classes.\n",
      "Using  1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# Set up the Resnet-18 model\n",
    "\n",
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model dev ...')\n",
    "\n",
    "# Grab the number of classes\n",
    "n_classes = ref_bal.class_code.unique().shape[0]\n",
    "print(f'There are {n_classes} roof type classes.')\n",
    "\n",
    "# Define the Resnet-18 model (in_channels = number of bands in the image)\n",
    "model = resnet18(n_classes, in_channels=8, pretrained=False)\n",
    "\n",
    "# Make model parallel and on GPU\n",
    "if torch.cuda.device_count() >= 1:\n",
    "    print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "else:\n",
    "    #ps_model = nn.DataParallel(ps_model)\n",
    "    model = nn.DataParallel(model)\n",
    "    print('Made cpu parallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b564fc-055b-4a85-97b6-0fc49b5167f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de33d04c-8d55-4079-9ad3-c1cc4e10df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4936, 4936, 4936, 1164, 814, 494]\n",
      "Class weights: tensor([ 3.5008,  3.5008,  3.5008, 14.8454, 21.2285, 34.9798], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Number of samples in each class\n",
    "val_counts = list(train_df['code'].value_counts())\n",
    "print(val_counts)\n",
    "\n",
    "total_samples = sum(val_counts)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = [total_samples / count for count in val_counts]\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Print the calculated class weights for verification\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ffb6c-d4a0-487b-9ae1-5243892b626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42775290-3fd6-4b70-9784-ede4e6bb2c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa012653-1a9f-4e0c-acb2-b8f1b6a6025b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e37d065-53ff-4e61-9b0d-0d0760e3c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_fun(trial):\n",
    "    \"\"\" Objective function for hyperparameter tuning \"\"\"\n",
    "    \"\"\"\n",
    "    Function for fine-tuning Resnet-18 model using 'optuna' Python package\n",
    "    Args:\n",
    "        - trial: Optuna trial\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters to test\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128)\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    momentum = trial.suggest_uniform('momentum', 0.8, 0.99)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
    "\n",
    "    # Load the train, test, and validation\n",
    "    train_loader = DataLoader(train_df, batch_size=batch_size, shuffle=True, collate_fn=make_good_batch)\n",
    "    val_loader = DataLoader(val_df, batch_size=batch_size, shuffle=False, collate_fn=make_good_batch)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(10):  # Adjust number of epochs as needed\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29799a6c-ad3e-46df-82e1-8df3faedc146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9cad24-4dad-4fa9-ac93-e88209ba7e4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create an Optuna study\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Display the best hyperparameters and accuracy\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Display the best hyperparameters and accuracy\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95d9c1a4-3107-4970-816e-c9a122ddeaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44372c84-5493-4675-816c-c03ca020749a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911efed-945d-49e3-a6ea-a2800e4bc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_fun, n_trials=50)\n",
    "\n",
    "t1 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time: {t1:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d0fc8-11b3-4ae8-9771-2ce256d4dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the best hyperparameters and accuracy\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best accuracy:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad061561-38d0-428b-80f2-8a07c8fc7f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49a87f-dc82-4d1f-b29d-ecb16a97bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7242b8aa-59fd-4eef-98e4-762e40b4740e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
