{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea6f7f5a-e411-45df-b25d-c461d6d0cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/results/resnet18-cv/\n",
      "Imports successful !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classifying roof materials for building footprints from trained ResNet-18 models\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, gc, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsat.models.classification import resnet18\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Custom functions (__functions.py)\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "homedir = '/home/jovyan' # cyverse\n",
    "\n",
    "# results_dir = os.path.join(maindir, 'results/resnet18/')\n",
    "results_dir = os.path.join(homedir, 'results/resnet18-cv/')\n",
    "print(results_dir)\n",
    "\n",
    "print(\"Imports successful !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e13273e-b85d-4273-bda6-9011f226e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec9d0-e485-43de-a674-11b089ce305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b9945-1891-4861-ada1-bbc177de5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MS building footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac52412-7d3d-438b-8ff7-510c2d13f1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((334794.168 4306846.311, 334799.662 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((334703.572 4306870.743, 334701.114 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((334666.123 4306432.288, 334671.751 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((334616.324 4306162.858, 334621.692 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((334622.665 4306603.184, 334630.936 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                           geometry\n",
       "0    1  POLYGON ((334794.168 4306846.311, 334799.662 4...\n",
       "1    2  POLYGON ((334703.572 4306870.743, 334701.114 4...\n",
       "2    3  POLYGON ((334666.123 4306432.288, 334671.751 4...\n",
       "3    4  POLYGON ((334616.324 4306162.858, 334621.692 4...\n",
       "4    5  POLYGON ((334622.665 4306603.184, 334630.936 4..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp = os.path.join(maindir, 'data/spatial/raw/dc_data/footprints/dc-ms_footprints.gpkg')\n",
    "fp = os.path.join(homedir, 'opp-data/dc-ms_footprints.gpkg')\n",
    "footprints = gpd.read_file(fp)\n",
    "footprints['uid'] = footprints.index + 1\n",
    "footprints = footprints[['uid', 'geometry']]\n",
    "footprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fd57ca-4032-4bc8-bedb-24200302d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:32618>\n",
       "Name: WGS 84 / UTM zone 18N\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Between 78°W and 72°W, northern hemisphere between equator and 84°N, onshore and offshore. Bahamas. Canada - Nunavut; Ontario; Quebec. Colombia. Cuba. Ecuador. Greenland. Haiti. Jamaica. Panama. Turks and Caicos Islands. United States (USA). Venezuela.\n",
       "- bounds: (-78.0, 0.0, -72.0, 84.0)\n",
       "Coordinate Operation:\n",
       "- name: UTM zone 18N\n",
       "- method: Transverse Mercator\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprints.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a5dc-b004-4789-ae19-5229c6ca8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf17997-cc95-4b0f-bb12-b5b86d9dabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled data as well (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e37f302-1aeb-4221-9ea8-8d4d7c975e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout set class distribution:\n",
      " class_code  code\n",
      "CS          0       7427\n",
      "ME          1       7373\n",
      "SL          2       3054\n",
      "UR          3        256\n",
      "WS          5        231\n",
      "TL          4        185\n",
      "SH          6        157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data\n",
    "# holdout_df = gpd.read_file(os.path.join(homedir,'results/resnet18/cv-results/dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "holdout_df = gpd.read_file(os.path.join(results_dir, 'dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "print(\"Holdout set class distribution:\\n\", holdout_df[['class_code','code']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ebcb8b-d03f-4ba6-a150-2610d863445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code map: \n",
      "{0: 'CS', 1: 'ME', 2: 'SL', 3: 'UR', 4: 'TL', 5: 'WS', 6: 'SH'}\n",
      "Description map: \n",
      "{0: 'Composition Shingle', 1: 'Metal', 2: 'Slate', 3: 'Urethane', 4: 'Tile', 5: 'Wood shake/shingle', 6: 'Shingle'}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for mapping\n",
    "code_mapping = dict(zip(holdout_df['code'], holdout_df['class_code']))  # Mapping to original 'class_code'\n",
    "desc_mapping = dict(zip(holdout_df['code'], holdout_df['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e5b4d-0625-4d3f-b747-bae45e703674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f74f8c-5a20-4dc5-9037-28f9fbfef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Planet imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe0b7f7-8c28-4580-b912-cf5983fc437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (14939, 6330)\n",
      "bands: 6\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (489558.0, 4383960.0, 508548.0, 4428777.0)\n",
      "sum: 15.8248291015625\n",
      "CRS: EPSG:32613\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 6, y: 14939, x: 6330)> Size: 2GB\n",
      "[567383220 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 48B 1 2 3 4 5 6\n",
      "  * x            (x) float64 51kB 4.896e+05 4.896e+05 ... 5.085e+05 5.085e+05\n",
      "  * y            (y) float64 120kB 4.429e+06 4.429e+06 ... 4.384e+06 4.384e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    long_name:      ('nir', 'NDBIbg', 'NDBIrg', 'NISI', 'MNF1', 'NISI5x5')\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "# stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da_fp = os.path.join(homedir,'opp-data/denver_0815_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2f3a8-13ea-45f0-976e-b84ce059a813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59417723-bfeb-4198-869a-d49cb60b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roof image dataset for inference (all MS building footprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af3fc73-0931-4082-b1c8-875c3163e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for all footprints !\n"
     ]
    }
   ],
   "source": [
    "footprints_ds = UnlabeledRoofImageDataset(footprints, img_path=stack_da_fp, n_bands=n_bands, img_dim=params['window_size'])\n",
    "dloader = DataLoader(\n",
    "    footprints_ds, \n",
    "    batch_size=params['batch_size'], \n",
    "    num_workers=2, \n",
    "    shuffle=False, \n",
    "    pin_memory=True\n",
    ")\n",
    "print(\"Data loaded for all footprints !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18eafa4-f677-4b31-a090-9bbaaa933792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad058ea1-d142-4394-9cb4-4282cbdb135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet-18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e68f3-3771-4727-8a13-77716be22079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cbb8eb4-e469-491f-9ed3-b2b7376c57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for model eval ...\n"
     ]
    }
   ],
   "source": [
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model eval ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b2970e-bcc3-401e-b48a-7790ab1b4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from path: /home/jovyan/results/resnet18-cv/dc-resnet18_fold4.pth\n",
      "\tMade GPU parallel.\n",
      "\tModel loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for the current fold\n",
    "best_fold = 4  # from holdout accuracy\n",
    "# model_fp = os.path.join(maindir,f'results/resnet18/cv-models/dc-resnet18_fold{best_fold}.pth')\n",
    "model_fp = os.path.join(results_dir, f'dc-resnet18_fold{best_fold}.pth')\n",
    "\n",
    "print(f\"Loading model from path: {model_fp}\")\n",
    "checkpoint = torch.load(model_fp, map_location=device)\n",
    "\n",
    "# Initialize the model architecture\n",
    "n_classes = len(code_mapping.keys())\n",
    "model, _, _, _ = initialize_resnet18(\n",
    "    n_classes=n_classes,\n",
    "    n_channels=n_bands,\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(\"\\tModel loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e21f2-acb4-41ff-ba8b-f34a973d89a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53cf992-bf2c-4b41-88a4-f5756eda02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of footprint dataset: 77851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>CS</th>\n",
       "      <th>ME</th>\n",
       "      <th>SL</th>\n",
       "      <th>UR</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_idx bbox prediction confidence   CS   ME   SL   UR   TL   WS   SH\n",
       "0       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "1       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "2       NaN  NaN        NaN        NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "n = footprints_ds.__len__() # length of the dataset\n",
    "class_labels = [code_mapping[i] for i in range(n_classes)]\n",
    "print(f\"Length of footprint dataset: {n}\")\n",
    "columns=['chunk_idx', 'bbox', 'prediction', 'confidence'] + class_labels\n",
    "res_df = pd.DataFrame(\n",
    "    columns=columns,\n",
    "    index=range(n)\n",
    ")\n",
    "res_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3255b37b-3a93-4bd9-a3b1-7d5441cdc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid sample at index: 64. Error: Invalid sample shape: (6, 0, 0)Skipping invalid sample at index: 0. Error: Invalid sample shape: (6, 0, 0)\n",
      "\n",
      "Skipping invalid sample at index: 128. Error: Invalid sample shape: (6, 0, 0)Skipping invalid sample at index: 192. Error: Invalid sample shape: (6, 0, 0)\n",
      "\n",
      "Skipping invalid sample at index: 256. Error: Invalid sample shape: (6, 0, 0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jovyan/opp-rooftop-mapping/code/__functions.py\", line 183, in __getitem__\n    return {'image': torch.from_numpy(sample).float(), 'bbox': bbox}\nTypeError: expected np.ndarray (got Tensor)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dloader):\n\u001b[1;32m      6\u001b[0m         image \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# retrieve the image chunks (unlabeled)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         bboxes \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Get the bounding boxes for the image chunks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/envs/rspy/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/jovyan/opp-rooftop-mapping/code/__functions.py\", line 183, in __getitem__\n    return {'image': torch.from_numpy(sample).float(), 'bbox': bbox}\nTypeError: expected np.ndarray (got Tensor)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(dloader):\n",
    "        image = sample['image'].to(device) # retrieve the image chunks (unlabeled)\n",
    "        bboxes = sample['bbox']  # Get the bounding boxes for the image chunks\n",
    "\n",
    "        # Make predictions\n",
    "        output = model(image.float())\n",
    "        probabilities = softmax(output, dim=1).cpu().numpy()  # Get probabilities for all classes\n",
    "        predictions = output.argmax(dim=1).cpu().numpy() # the predicted class\n",
    "        confidence = probabilities.max(axis=1)  # max probability for the predicted class\n",
    "\n",
    "        # Assign predictions and probabilities to all footprints that intersect with the bounding box\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            prob_dict = {code_mapping[j]: probabilities[i, j] for j in range(n_classes)}  # Use class names as column headers\n",
    "            res_df = res_df.append({\n",
    "                'chunk_idx': batch_idx * params['batch_size'] + i,  # Optional chunk ID\n",
    "                'bbox': bbox,  # Bounding box of the chunk\n",
    "                'prediction': code_mapping[predictions[i]],  # Map prediction to class name\n",
    "                'confidence': confidence[i],\n",
    "                **prob_dict  # Include all class probabilities with class names as column headers\n",
    "            }, ignore_index=True)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\tProcessed {batch_idx * params['batch_size']} samples.\")\n",
    "\n",
    "        # Clear GPU memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time for inference: {t2:.2f} minutes.\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e619376-4490-4140-a887-e7dde8c4779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = os.path.join(results_dir,'classification/dc-resnet18-inference_ms-footprints.csv')\n",
    "res_df.to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d400536-86b7-47fe-a7b4-debe0e9e5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2ec4c-9fb9-492a-a475-794b91bd6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
