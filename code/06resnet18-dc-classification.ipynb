{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea6f7f5a-e411-45df-b25d-c461d6d0cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/results/resnet18-cv/\n",
      "Imports successful !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classifying roof materials for building footprints from trained ResNet-18 models\n",
    "Author: maxwell.cook@colorado.edu\n",
    "\"\"\"\n",
    "\n",
    "import sys, os, gc, time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsat.models.classification import resnet18\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Custom functions (__functions.py)\n",
    "sys.path.append(os.path.join(os.getcwd(),'code/'))\n",
    "from __functions import *\n",
    "\n",
    "maindir = '/Users/max/Library/CloudStorage/OneDrive-Personal/mcook/earth-lab/opp-rooftop-mapping'\n",
    "homedir = '/home/jovyan' # cyverse\n",
    "\n",
    "# results_dir = os.path.join(maindir, 'results/resnet18/')\n",
    "results_dir = os.path.join(homedir, 'results/resnet18-cv/')\n",
    "print(results_dir)\n",
    "\n",
    "print(\"Imports successful !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e13273e-b85d-4273-bda6-9011f226e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best params from tuning\n",
    "params = {'window_size': 78, 'batch_size': 64, 'learning_rate': 0.01, 'weight_decay': 0.01, 'momentum': 0.85, 'patience': 5}\n",
    "print(f'Model params: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec9d0-e485-43de-a674-11b089ce305f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b9945-1891-4861-ada1-bbc177de5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MS building footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aac52412-7d3d-438b-8ff7-510c2d13f1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((334794.168 4306846.311, 334799.662 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((334703.572 4306870.743, 334701.114 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((334666.123 4306432.288, 334671.751 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((334616.324 4306162.858, 334621.692 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((334622.665 4306603.184, 334630.936 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                           geometry\n",
       "0    1  POLYGON ((334794.168 4306846.311, 334799.662 4...\n",
       "1    2  POLYGON ((334703.572 4306870.743, 334701.114 4...\n",
       "2    3  POLYGON ((334666.123 4306432.288, 334671.751 4...\n",
       "3    4  POLYGON ((334616.324 4306162.858, 334621.692 4...\n",
       "4    5  POLYGON ((334622.665 4306603.184, 334630.936 4..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fp = os.path.join(maindir, 'data/spatial/raw/dc_data/footprints/dc-ms_footprints.gpkg')\n",
    "fp = os.path.join(homedir, 'opp-data/dc-ms_footprints.gpkg')\n",
    "footprints = gpd.read_file(fp)\n",
    "footprints['uid'] = footprints.index + 1\n",
    "footprints = footprints[['uid', 'geometry']]\n",
    "footprints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4fd57ca-4032-4bc8-bedb-24200302d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:32618>\n",
       "Name: WGS 84 / UTM zone 18N\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- name: Between 78°W and 72°W, northern hemisphere between equator and 84°N, onshore and offshore. Bahamas. Canada - Nunavut; Ontario; Quebec. Colombia. Cuba. Ecuador. Greenland. Haiti. Jamaica. Panama. Turks and Caicos Islands. United States (USA). Venezuela.\n",
       "- bounds: (-78.0, 0.0, -72.0, 84.0)\n",
       "Coordinate Operation:\n",
       "- name: UTM zone 18N\n",
       "- method: Transverse Mercator\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footprints.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a5dc-b004-4789-ae19-5229c6ca8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf17997-cc95-4b0f-bb12-b5b86d9dabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sampled data as well (holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e37f302-1aeb-4221-9ea8-8d4d7c975e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout set class distribution:\n",
      " class_code  code\n",
      "CS          0       7427\n",
      "ME          1       7373\n",
      "SL          2       3054\n",
      "UR          3        256\n",
      "WS          5        231\n",
      "TL          4        185\n",
      "SH          6        157\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the holdout data\n",
    "# holdout_df = gpd.read_file(os.path.join(homedir,'results/resnet18/cv-results/dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "holdout_df = gpd.read_file(os.path.join(results_dir, 'dc-resnet18_cv_holdout_ref.gpkg'))\n",
    "print(\"Holdout set class distribution:\\n\", holdout_df[['class_code','code']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ebcb8b-d03f-4ba6-a150-2610d863445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code map: \n",
      "{0: 'CS', 1: 'ME', 2: 'SL', 3: 'UR', 4: 'TL', 5: 'WS', 6: 'SH'}\n",
      "Description map: \n",
      "{0: 'Composition Shingle', 1: 'Metal', 2: 'Slate', 3: 'Urethane', 4: 'Tile', 5: 'Wood shake/shingle', 6: 'Shingle'}\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for mapping\n",
    "code_mapping = dict(zip(holdout_df['code'], holdout_df['class_code']))  # Mapping to original 'class_code'\n",
    "desc_mapping = dict(zip(holdout_df['code'], holdout_df['description']))\n",
    "print(f'Code map: \\n{code_mapping}\\nDescription map: \\n{desc_mapping}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e5b4d-0625-4d3f-b747-bae45e703674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f74f8c-5a20-4dc5-9037-28f9fbfef1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Planet imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abe0b7f7-8c28-4580-b912-cf5983fc437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (8223, 6714)\n",
      "bands: 6\n",
      "resolution: (3.0, -3.0)\n",
      "bounds: (315267.0, 4294629.0, 335409.0, 4319298.0)\n",
      "sum: 8.181640625\n",
      "CRS: EPSG:32618\n",
      "NoData: None\n",
      "Array: <xarray.DataArray (band: 6, y: 8223, x: 6714)> Size: 1GB\n",
      "[331255332 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * band         (band) int64 48B 1 2 3 4 5 6\n",
      "  * x            (x) float64 54kB 3.153e+05 3.153e+05 ... 3.354e+05 3.354e+05\n",
      "  * y            (y) float64 66kB 4.319e+06 4.319e+06 ... 4.295e+06 4.295e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    AREA_OR_POINT:  Area\n",
      "    scale_factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    long_name:      ('nir', 'NDBIbg', 'NDBIrg', 'NISI', 'MNF1', 'NISI5x5')\n"
     ]
    }
   ],
   "source": [
    "# Load our image data to check on the format\n",
    "# stack_da_fp = os.path.join(maindir,'data/spatial/mod/dc_data/planet-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da_fp = os.path.join(homedir,'opp-data/dc_0623_psscene8b_final_norm.tif')\n",
    "stack_da = rxr.open_rasterio(stack_da_fp, mask=True, cache=False).squeeze()\n",
    "n_bands = stack_da.values.shape[:1][0] # get a list of band names\n",
    "print(\n",
    "    f\"shape: {stack_da.rio.shape}\\n\"\n",
    "    f\"bands: {n_bands}\\n\"\n",
    "    f\"resolution: {stack_da.rio.resolution()}\\n\"\n",
    "    f\"bounds: {stack_da.rio.bounds()}\\n\"\n",
    "    f\"sum: {stack_da.sum().item()}\\n\"\n",
    "    f\"CRS: {stack_da.rio.crs}\\n\"\n",
    "    f\"NoData: {stack_da.rio.nodata}\\n\"\n",
    "    f\"Array: {stack_da}\"\n",
    ")\n",
    "del stack_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2f3a8-13ea-45f0-976e-b84ce059a813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59417723-bfeb-4198-869a-d49cb60b442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the roof image dataset for inference (all MS building footprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3709bb22-0465-4a09-967b-5267a52f3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom collate function to handle Tensors and shapely.geometry.Polygon objects\n",
    "def custom_collate(batch):\n",
    "    images = torch.stack([item['image'] for item in batch], dim=0)  # Batch the images (Tensors)\n",
    "    bboxes = [item['bbox'] for item in batch]  # Keep bounding boxes as a list (don't batch them)\n",
    "    return {'image': images, 'bbox': bboxes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7af3fc73-0931-4082-b1c8-875c3163e5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for all footprints !\n"
     ]
    }
   ],
   "source": [
    "footprints_ds = UnlabeledRoofImageDataset(footprints, img_path=stack_da_fp, n_bands=n_bands, img_dim=params['window_size'])\n",
    "dloader = DataLoader(\n",
    "    footprints_ds, \n",
    "    batch_size=params['batch_size']*2, \n",
    "    num_workers=2, \n",
    "    shuffle=False, \n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate # allow retrieving the bbox\n",
    ")\n",
    "print(\"Data loaded for all footprints !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18eafa4-f677-4b31-a090-9bbaaa933792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad058ea1-d142-4394-9cb4-4282cbdb135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ResNet-18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e68f3-3771-4727-8a13-77716be22079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cbb8eb4-e469-491f-9ed3-b2b7376c57d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for model eval ...\n"
     ]
    }
   ],
   "source": [
    "# Define whether to leverage cpu or gpu (for my local machine it is only cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # get device for gpu or cpu\n",
    "print(f'Using {device} for model eval ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77b2970e-bcc3-401e-b48a-7790ab1b4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from path: /home/jovyan/results/resnet18-cv/dc-resnet18_fold4.pth\n",
      "\tMade GPU parallel.\n",
      "\tModel loaded !\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model for the current fold\n",
    "best_fold = 4  # from holdout accuracy\n",
    "# model_fp = os.path.join(maindir,f'results/resnet18/cv-models/dc-resnet18_fold{best_fold}.pth')\n",
    "model_fp = os.path.join(results_dir, f'dc-resnet18_fold{best_fold}.pth')\n",
    "\n",
    "print(f\"Loading model from path: {model_fp}\")\n",
    "checkpoint = torch.load(model_fp, map_location=device)\n",
    "\n",
    "# Initialize the model architecture\n",
    "n_classes = len(code_mapping.keys())\n",
    "model, _, _, _ = initialize_resnet18(\n",
    "    n_classes=n_classes,\n",
    "    n_channels=n_bands,\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(\"\\tModel loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e21f2-acb4-41ff-ba8b-f34a973d89a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e53cf992-bf2c-4b41-88a4-f5756eda02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of footprint dataset: 77851\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>CS</th>\n",
       "      <th>ME</th>\n",
       "      <th>SL</th>\n",
       "      <th>UR</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [chunk_idx, bbox, prediction, confidence, CS, ME, SL, UR, TL, WS, SH]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to store the results\n",
    "n = footprints_ds.__len__() # length of the dataset\n",
    "print(f\"Length of footprint dataset: {n}\")\n",
    "class_labels = [code_mapping[i] for i in range(n_classes)]\n",
    "columns = ['chunk_idx', 'bbox', 'prediction', 'confidence'] + class_labels\n",
    "res_df = pd.DataFrame(columns=columns)\n",
    "res_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3255b37b-3a93-4bd9-a3b1-7d5441cdc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessed 0 samples.\n",
      "\tProcessed 640 samples.\n",
      "\tProcessed 1280 samples.\n",
      "\tProcessed 1920 samples.\n",
      "\tProcessed 2560 samples.\n",
      "\tProcessed 3200 samples.\n",
      "\tProcessed 3840 samples.\n",
      "\tProcessed 4480 samples.\n",
      "\tProcessed 5120 samples.\n",
      "\tProcessed 5760 samples.\n",
      "\tProcessed 6400 samples.\n",
      "\tProcessed 7040 samples.\n",
      "\tProcessed 7680 samples.\n",
      "\tProcessed 8320 samples.\n",
      "\tProcessed 8960 samples.\n",
      "\tProcessed 9600 samples.\n",
      "\tProcessed 10240 samples.\n",
      "\tProcessed 10880 samples.\n",
      "\tProcessed 11520 samples.\n",
      "\tProcessed 12160 samples.\n",
      "\tProcessed 12800 samples.\n",
      "\tProcessed 13440 samples.\n",
      "\tProcessed 14080 samples.\n",
      "\tProcessed 14720 samples.\n",
      "\tProcessed 15360 samples.\n",
      "\tProcessed 16000 samples.\n",
      "\tProcessed 16640 samples.\n",
      "\tProcessed 17280 samples.\n",
      "\tProcessed 17920 samples.\n",
      "\tProcessed 18560 samples.\n",
      "\tProcessed 19200 samples.\n",
      "\tProcessed 19840 samples.\n",
      "\tProcessed 20480 samples.\n",
      "\tProcessed 21120 samples.\n",
      "\tProcessed 21760 samples.\n",
      "\tProcessed 22400 samples.\n",
      "\tProcessed 23040 samples.\n",
      "\tProcessed 23680 samples.\n",
      "\tProcessed 24320 samples.\n",
      "\tProcessed 24960 samples.\n",
      "\tProcessed 25600 samples.\n",
      "\tProcessed 26240 samples.\n",
      "\tProcessed 26880 samples.\n",
      "\tProcessed 27520 samples.\n",
      "\tProcessed 28160 samples.\n",
      "\tProcessed 28800 samples.\n",
      "\tProcessed 29440 samples.\n",
      "\tProcessed 30080 samples.\n",
      "\tProcessed 30720 samples.\n",
      "\tProcessed 31360 samples.\n",
      "\tProcessed 32000 samples.\n",
      "\tProcessed 32640 samples.\n",
      "\tProcessed 33280 samples.\n",
      "\tProcessed 33920 samples.\n",
      "\tProcessed 34560 samples.\n",
      "\tProcessed 35200 samples.\n",
      "\tProcessed 35840 samples.\n",
      "\tProcessed 36480 samples.\n",
      "\tProcessed 37120 samples.\n",
      "\tProcessed 37760 samples.\n",
      "\tProcessed 38400 samples.\n",
      "\n",
      "~~~~~~~~~~\n",
      "\n",
      "Total elapsed time for inference: 9.89 minutes.\n",
      "\n",
      "~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, sample in enumerate(dloader):\n",
    "        image = sample['image'].to(device) # retrieve the image chunks (unlabeled)\n",
    "        bboxes = sample['bbox']  # Get the bounding boxes for the image chunks\n",
    "\n",
    "        # Make predictions\n",
    "        output = model(image.float())\n",
    "        probabilities = softmax(output, dim=1).cpu().numpy()  # Get probabilities for all classes\n",
    "        predictions = output.argmax(dim=1).cpu().numpy() # the predicted class\n",
    "        confidence = probabilities.max(axis=1)  # max probability for the predicted class\n",
    "\n",
    "        # Assign predictions and probabilities to all footprints that intersect with the bounding box\n",
    "        batch_results = [] # store results for each chunk\n",
    "        for i, bbox in enumerate(bboxes):\n",
    "            prob_dict = {code_mapping[j]: probabilities[i, j] for j in range(n_classes)}  # Use class names as column headers\n",
    "            batch_results.append({\n",
    "                'chunk_idx': batch_idx * params['batch_size'] + i,  # Optional chunk ID\n",
    "                'bbox': bbox,  # Bounding box of the chunk\n",
    "                'prediction': code_mapping[predictions[i]],  # Map prediction to class name\n",
    "                'confidence': confidence[i],\n",
    "                **prob_dict  # Include all class probabilities with class names as column headers\n",
    "            })\n",
    "\n",
    "        batch_df = pd.DataFrame(batch_results)\n",
    "        res_df = pd.concat([res_df, batch_df], ignore_index=True)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"\\tProcessed {batch_idx * params['batch_size']} samples.\")\n",
    "\n",
    "        # Clear GPU memory after each batch\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "print(\"\\n~~~~~~~~~~\\n\")\n",
    "t2 = (time.time() - t0) / 60\n",
    "print(f\"Total elapsed time for inference: {t2:.2f} minutes.\")\n",
    "print(\"\\n~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09b3a12c-eacb-4931-b264-b7fc67fe2116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_idx</th>\n",
       "      <th>bbox</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>CS</th>\n",
       "      <th>ME</th>\n",
       "      <th>SL</th>\n",
       "      <th>UR</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((334917 4306731, 334917 4306965, 3346...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>0.988314</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.008327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((334812 4306749, 334812 4306983, 3345...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.997035</td>\n",
       "      <td>0.997035</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((334782 4306323, 334782 4306557, 3345...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.629269</td>\n",
       "      <td>0.629269</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.076365</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.266676</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.016858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((334731 4306053, 334731 4306287, 3344...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.931676</td>\n",
       "      <td>0.931676</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.055915</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((334740 4306494, 334740 4306728, 3345...</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.950600</td>\n",
       "      <td>0.950600</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_idx                                               bbox prediction  \\\n",
       "0         0  POLYGON ((334917 4306731, 334917 4306965, 3346...         CS   \n",
       "1         1  POLYGON ((334812 4306749, 334812 4306983, 3345...         CS   \n",
       "2         2  POLYGON ((334782 4306323, 334782 4306557, 3345...         CS   \n",
       "3         3  POLYGON ((334731 4306053, 334731 4306287, 3344...         CS   \n",
       "4         4  POLYGON ((334740 4306494, 334740 4306728, 3345...         CS   \n",
       "\n",
       "   confidence        CS        ME        SL        UR        TL        WS  \\\n",
       "0    0.988314  0.988314  0.001325  0.001592  0.000181  0.000233  0.000027   \n",
       "1    0.997035  0.997035  0.000732  0.000694  0.000014  0.000092  0.001233   \n",
       "2    0.629269  0.629269  0.006650  0.076365  0.001589  0.266676  0.002593   \n",
       "3    0.931676  0.931676  0.002242  0.055915  0.002766  0.001167  0.005692   \n",
       "4    0.950600  0.950600  0.010073  0.030565  0.000514  0.003937  0.000123   \n",
       "\n",
       "         SH  \n",
       "0  0.008327  \n",
       "1  0.000200  \n",
       "2  0.016858  \n",
       "3  0.000543  \n",
       "4  0.004187  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e619376-4490-4140-a887-e7dde8c4779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = os.path.join(results_dir,'classification/')\n",
    "if not os.path.exists(out_fp):\n",
    "    os.makedirs(out_fp)\n",
    "out_fp = os.path.join(out_fp,'dc-resnet18-inference_ms-footprints.csv')\n",
    "res_df.to_csv(out_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d400536-86b7-47fe-a7b4-debe0e9e5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2ec4c-9fb9-492a-a475-794b91bd6925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to footprint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663ce2d-59f5-4ab6-80a0-f5d07edd045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4460219c-5b77-45c4-ad22-412066666418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "      <th>CS</th>\n",
       "      <th>ME</th>\n",
       "      <th>SL</th>\n",
       "      <th>UR</th>\n",
       "      <th>TL</th>\n",
       "      <th>WS</th>\n",
       "      <th>SH</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.938670</td>\n",
       "      <td>0.932819</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.002956</td>\n",
       "      <td>0.032270</td>\n",
       "      <td>0.020047</td>\n",
       "      <td>POLYGON ((334794.168 4306846.311, 334799.662 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.951564</td>\n",
       "      <td>0.951138</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>POLYGON ((334703.572 4306870.743, 334701.114 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.855312</td>\n",
       "      <td>0.836960</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.113026</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.021802</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>POLYGON ((334666.123 4306432.288, 334671.751 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.827656</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.025353</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>POLYGON ((334616.324 4306162.858, 334621.692 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CS</td>\n",
       "      <td>0.942368</td>\n",
       "      <td>0.930119</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.011083</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>POLYGON ((334622.665 4306603.184, 334630.936 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid prediction  confidence        CS        ME        SL        UR  \\\n",
       "0    1         CS    0.938670  0.932819  0.004881  0.005791  0.001234   \n",
       "1    2         CS    0.951564  0.951138  0.003498  0.004728  0.001179   \n",
       "2    3         CS    0.855312  0.836960  0.005624  0.113026  0.002095   \n",
       "3    4         CS    0.829231  0.827656  0.004210  0.126863  0.001677   \n",
       "4    5         CS    0.942368  0.930119  0.012943  0.015518  0.019357   \n",
       "\n",
       "         TL        WS        SH  \\\n",
       "0  0.002956  0.032270  0.020047   \n",
       "1  0.001276  0.015694  0.022486   \n",
       "2  0.009412  0.021802  0.011080   \n",
       "3  0.003047  0.025353  0.011194   \n",
       "4  0.002538  0.011083  0.008442   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((334794.168 4306846.311, 334799.662 4...  \n",
       "1  POLYGON ((334703.572 4306870.743, 334701.114 4...  \n",
       "2  POLYGON ((334666.123 4306432.288, 334671.751 4...  \n",
       "3  POLYGON ((334616.324 4306162.858, 334621.692 4...  \n",
       "4  POLYGON ((334622.665 4306603.184, 334630.936 4...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert results to a GeoDataFrame\n",
    "res_gdf = gpd.GeoDataFrame(res_df, geometry=res_df['bbox'], crs=footprints.crs)\n",
    "\n",
    "# Perform a spatial join to the footprints\n",
    "res_gdf_footprints = gpd.sjoin(footprints, res_gdf, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "# Group by footprint UID and calculate the mean of probabilities for overlapping chunks\n",
    "agg_dict = {class_name: 'mean' for class_name in class_labels}\n",
    "agg_dict.update({\n",
    "    'confidence': 'mean',  # Calculate mean confidence\n",
    "    'prediction': lambda x: x.mode()[0]  # Use the most common prediction (mode)\n",
    "})\n",
    "\n",
    "# Aggregate by footprint ID\n",
    "agg_results = res_gdf_footprints.groupby('uid').agg(agg_dict).reset_index()\n",
    "# Merge back to the original footprint data\n",
    "inference_results = footprints.merge(agg_results, on='uid', how='left')\n",
    "inference_results = inference_results[['uid','prediction','confidence']+class_labels+['geometry']] \t\n",
    "\n",
    "inference_results.to_file(os.path.join(results_dir, 'dc-resnet18-inference_ms-footprints_mean.gpkg'), driver='GPKG')\n",
    "inference_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60129f0f-7d51-45b3-959a-1105e6f66aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5bdb3d-f72e-468a-8141-0be069af885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the reference data to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01699d1-8973-49b9-aaf7-70075c74adda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622122f1-2eec-41ca-bd57-f74bf6479c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data (footprints)\n",
    "# gdf_path = os.path.join(maindir,'data/spatial/mod/dc_data/training/dc_data_reference_footprints.gpkg')\n",
    "gdf_path = join(homedir,'opp-data/dc_data_reference_footprints.gpkg')\n",
    "ref = gpd.read_file(gdf_path)\n",
    "ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d5199e-6fdd-41f1-875c-128c64e45855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to the classified footprints by centroid\n",
    "ref['geometry'] = ref.geometry.centorid\n",
    "inference_ref = sjoin(inference_results, ref, how='left', predicate='within')\n",
    "inference_ref.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8517cc-6fb9-4d82-933a-8c0bb1ef216e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513b5ab3-d5af-464c-bd42-6c855961afc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82c7813e-bd07-4426-b399-b8a83e3e360d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rspy",
   "language": "python",
   "name": "rspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
